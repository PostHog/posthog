---
title: Anthropic LLM analytics installation
showStepsToc: true
---

import LLMsSDKsCallout from './_snippets/llms-sdks-callout.mdx'
import VerifyLLMEventsStep from './_snippets/verify-llm-events-step.mdx'
import NotableGenerationProperties from '../_snippets/notable-generation-properties.mdx'

<Steps>

<Step title="Install the PostHog SDK" badge="required">

Setting up analytics starts with installing the PostHog SDK for your language. LLM analytics works best with our Python and Node SDKs.

<MultiLanguage>

```bash file="Python"
pip install posthog
```

```bash file="Node"
npm install @posthog/ai posthog-node
```

</MultiLanguage>

</Step>

<Step title="Install the Anthropic SDK" badge="required">

Install the Anthropic SDK:

<MultiLanguage>

```bash file="Python"
pip install anthropic
```

```bash file="Node"
npm install @anthropic-ai/sdk
```

</MultiLanguage>

<LLMsSDKsCallout />

</Step>

<Step title="Initialize PostHog and the Anthropic wrapper" badge="required">

Initialize PostHog with your project API key and host from [your project settings](https://app.posthog.com/settings/project), then pass it to our Anthropic wrapper.

<MultiLanguage>

```python
from posthog.ai.anthropic import Anthropic
from posthog import Posthog

posthog = Posthog(
    "<ph_project_api_key>",
    host="<ph_client_api_host>"
)

client = Anthropic(
    api_key="sk-ant-api...", # Replace with your Anthropic API key
    posthog_client=posthog # This is an optional parameter. If it is not provided, a default client will be used.
)
```

```typescript
import { Anthropic } from '@posthog/ai'
import { PostHog } from 'posthog-node'

const phClient = new PostHog(
  '<ph_project_api_key>',
  { host: '<ph_client_api_host>' }
)

const client = new Anthropic({
  apiKey: 'sk-ant-api...', // Replace with your Anthropic API key
  posthog: phClient
})
```

</MultiLanguage>

> **Note:** This also works with the `AsyncAnthropic` client as well as `AnthropicBedrock`, `AnthropicVertex`, and the async versions of those.

</Step>

<Step title="Call Anthropic LLMs" badge="required">

Now, when you use the Anthropic SDK to call LLMs, PostHog automatically captures an `$ai_generation` event.

You can enrich the event with additional data such as the trace ID, distinct ID, custom properties, groups, and privacy mode options.

<MultiLanguage>

```python
response = client.messages.create(
    model="claude-3-opus-20240229",
    messages=[
        {
            "role": "user",
            "content": "Tell me a fun fact about hedgehogs"
        }
    ],
    posthog_distinct_id="user_123", # optional
    posthog_trace_id="trace_123", # optional
    posthog_properties={"conversation_id": "abc123", "paid": True}, # optional
    posthog_groups={"company": "company_id_in_your_db"},  # optional 
    posthog_privacy_mode=False # optional
)

print(response.content[0].text)
```

```typescript
const response = await client.messages.create({
  model: "claude-3-5-sonnet-latest",
  messages: [
    {
      role: "user",
      content: "Tell me a fun fact about hedgehogs"
    }
  ],
  posthogDistinctId: "user_123", // optional
  posthogTraceId: "trace_123", // optional
  posthogProperties: { conversationId: "abc123", paid: true }, // optional
  posthogGroups: { company: "company_id_in_your_db" }, // optional
  posthogPrivacyMode: false // optional
})

console.log(response.content[0].text)
phClient.shutdown() 
```

</MultiLanguage>

> **Notes:**
>
> - This also works when message streams are used (e.g. `stream=True` or `client.messages.stream(...)`).
> - If you want to capture LLM events anonymously, **don't** pass a distinct ID to the request. See our docs on [anonymous vs identified events](/docs/data/anonymous-vs-identified-events) to learn more.

You can expect captured `$ai_generation` events to have the following properties:

<NotableGenerationProperties />

</Step>

<VerifyLLMEventsStep />

</Steps>

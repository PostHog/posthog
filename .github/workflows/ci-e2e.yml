#
# This workflow runs CI E2E tests with Cypress.
#
# It relies on the container image built by 'container-images-ci.yml'.
#
name: E2E CI

on:
    pull_request:

concurrency:
    group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
    cancel-in-progress: true

jobs:
    cypress_prep:
        name: Cypress preparation
        runs-on: ubuntu-latest
        timeout-minutes: 30
        outputs:
            specs: ${{ steps.set-specs.outputs.specs }}

        steps:
            - name: Wait for the container image cache to be ready
              uses: lewagon/wait-on-check-action@v1.2.0
              with:
                  check-name: Build PostHog
                  ref: ${{ github.event.pull_request.head.sha }}
                  repo-token: ${{ secrets.GITHUB_TOKEN }}
                  wait-interval: 10

            - name: Checkout code
              uses: actions/checkout@v3

            - name: List cypress/e2e and produce a JSON array of the files, in chunks
              id: set-specs
              run: echo "specs=$(ls cypress/e2e/* | jq --slurp --raw-input -c 'split("\n")[:-1] | _nwise(3) | join("\n")' | jq --slurp -c .)" >> $GITHUB_OUTPUT





    cypress:
        name: Cypress E2E tests (${{ strategy.job-index }})
        runs-on: ubuntu-latest
        timeout-minutes: 30
        needs: [cypress_prep]
        strategy:
            # when one test fails, DO NOT cancel the other
            # containers, as there may be other spec failures
            # we want to know about.
            fail-fast: false
            matrix:
                specs: ${{ fromJson(needs.cypress_prep.outputs.specs) }}

        steps:
            - name: Checkout
              uses: actions/checkout@v3

            - name: Install pnpm
              uses: pnpm/action-setup@v2
              with:
                  version: 7.x.x

            - name: Set up Node.js
              uses: actions/setup-node@v3
              with:
                  node-version: 18

            - name: Get pnpm cache directory path
              id: pnpm-cache-dir
              run: echo "PNPM_STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

            - name: Get cypress cache directory path
              id: cypress-cache-dir
              run: echo "CYPRESS_BIN_PATH=$(npx cypress cache path)" >> $GITHUB_OUTPUT

            - uses: actions/cache@v3
              id: pnpm-cache
              with:
                  path: |
                      ${{ steps.pnpm-cache-dir.outputs.PNPM_STORE_PATH }}
                      ${{ steps.cypress-cache-dir.outputs.CYPRESS_BIN_PATH }}
                  key: ${{ runner.os }}-pnpm-cypress-${{ hashFiles('**/pnpm-lock.yaml') }}
                  restore-keys: |
                      ${{ runner.os }}-pnpm-cypress-

            - name: Install package.json dependencies with pnpm
              run: pnpm install --frozen-lockfile

            - name: Stop/Start stack with Docker Compose
              run: |
                  docker compose -f docker-compose.dev.yml down
                  docker compose -f docker-compose.dev.yml up -d

            - name: Wait for ClickHouse
              run: ./bin/check_kafka_clickhouse_up

            - name: Setup env
              run: |
                  cat <<EOT >> .env
                  SECRET_KEY=6b01eee4f945ca25045b5aab440b953461faf08693a9abbf1166dc7c6b9772da
                  REDIS_URL=redis://localhost
                  DATABASE_URL=postgres://posthog:posthog@localhost:5432/posthog
                  KAFKA_URL=kafka://kafka:9092
                  DISABLE_SECURE_SSL_REDIRECT=1
                  SECURE_COOKIES=0
                  OPT_OUT_CAPTURE=1
                  SELF_CAPTURE=0
                  E2E_TESTING=1
                  EMAIL_HOST=email.test.posthog.net
                  SITE_URL=http://localhost:8000
                  NO_RESTART_LOOP=1
                  CLICKHOUSE_SECURE=0
                  OBJECT_STORAGE_ENABLED=1
                  OBJECT_STORAGE_ENDPOINT=http://localhost:19000
                  OBJECT_STORAGE_ACCESS_KEY_ID=object_storage_root_user
                  OBJECT_STORAGE_SECRET_ACCESS_KEY=object_storage_root_password
                  EOT

            - name: Docker meta
              id: meta
              uses: docker/metadata-action@v4
              with:
                  images: ghcr.io/posthog/posthog/posthog # keep this in sync with the 'Container Images CI / Build PostHog' job

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v2

            - name: Set up QEMU
              uses: docker/setup-qemu-action@v2

            - name: Set up Depot CLI
              uses: depot/setup-action@v1

            - name: Login to GitHub Container Registry
              uses: docker/login-action@v2
              with:
                  registry: ghcr.io
                  username: ${{ github.actor }}
                  password: ${{ secrets.GITHUB_TOKEN }}

            - name: Build container images
              id: build
              uses: depot/build-push-action@v1
              with:
                  # Why are we re-building the image instead of pulling it from a repository?
                  # Because PRs from external contributors will not be able to do so. Instead,
                  # we build the image in the 'Container Images CI / Build PostHog' job, caching
                  # the layers to the GHA backend so that we can re-use those here.
                  project: x19jffd9zf # posthog
                  buildx-fallback: true # fallback to using 'docker buildx build' if 'depot build' is unable to acquire a builder connection
                  cache-from: type=gha # always pull the layers from GHA
                  cache-to: type=gha,mode=max # always push the layers to GHA
                  push: false
                  tags: ${{ steps.meta.outputs.tags }}
                  platforms: linux/amd64,linux/arm64

            - name: Start PostHog
              run: |
                  mkdir -p /tmp/logs

                  echo "Starting PostHog using the container image ${{ steps.meta.outputs.tags }}"
                  DOCKER_RUN="docker run --rm --network host --add-host kafka:127.0.0.1 --env-file .env ${{ steps.meta.outputs.tags }}"

                  $DOCKER_RUN ./bin/migrate
                  $DOCKER_RUN python manage.py setup_dev

                  $DOCKER_RUN ./bin/docker-worker &> /tmp/logs/worker.txt &
                  $DOCKER_RUN ./bin/docker-server &> /tmp/logs/server.txt &

            - name: Cypress run
              uses: cypress-io/github-action@v5
              with:
                  config-file: cypress.e2e.config.ts
                  config: retries=2
                  spec: ${{ matrix.specs }}
                  install: false

            - name: Archive test screenshots
              uses: actions/upload-artifact@v3
              with:
                  name: screenshots
                  path: cypress/screenshots
              if: ${{ failure() }}

            - name: Archive test downloads
              uses: actions/upload-artifact@v3
              with:
                  name: downloads
                  path: cypress/downloads
              if: ${{ failure() }}

            - name: Archive test videos
              uses: actions/upload-artifact@v3
              with:
                  name: videos
                  path: cypress/videos
              if: ${{ failure() }}

            - name: Archive accessibility violations
              uses: actions/upload-artifact@v3
              with:
                  name: accessibility-violations
                  path: '**/a11y/'
                  if-no-files-found: 'ignore'

            - name: Show logs on failure
              # use artefact here, as I think the output will be too large for display in an action
              uses: actions/upload-artifact@v3
              with:
                  name: logs
                  path: /tmp/logs
              if: ${{ failure() }}

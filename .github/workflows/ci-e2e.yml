#
# This workflow runs CI E2E tests with Cypress.
#
# It relies on the container image built by 'container-images-ci.yml'.
#
name: E2E CI

on:
    pull_request:

concurrency:
    group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
    cancel-in-progress: true

jobs:
    changes:
        runs-on: ubuntu-24.04
        timeout-minutes: 5
        name: Determine need to run E2E checks
        # Set job outputs to values from filter step
        outputs:
            shouldTriggerCypress: ${{ steps.changes.outputs.shouldTriggerCypress }}
        steps:
            # For pull requests it's not necessary to check out the code
            - uses: dorny/paths-filter@4512585405083f25c027a35db413c2b3b9006d50 # v2
              id: changes
              with:
                  filters: |
                      shouldTriggerCypress:
                        # Avoid running E2E tests for irrelevant changes
                        # NOTE: we are at risk of missing a dependency here. We could make
                        # the dependencies more clear if we separated the backend/frontend
                        # code completely
                        - 'ee/**'
                        - 'posthog/!(temporal/**)/**'
                        - 'bin/*'
                        - frontend/**/*
                        - requirements.txt
                        - requirements-dev.txt
                        - package.json
                        - pnpm-lock.yaml
                        - .github/actions/build-n-cache-image/action.yml
                        - .github/workflows/ci-e2e.yml
                        # We use docker compose for tests, make sure we rerun on
                        # changes to docker-compose.dev.yml e.g. dependency
                        # version changes
                        - docker-compose.dev.yml
                        - Dockerfile

    # Job that lists and chunks spec file names and caches node modules
    chunks:
        needs: changes
        name: Cypress preparation
        runs-on: ubuntu-24.04
        timeout-minutes: 5
        outputs:
            chunks: ${{ steps.chunk.outputs.chunks }}
        steps:
            - name: Check out
              uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3

            - name: Group spec files into chunks of three
              id: chunk
              run: |
                  cd cypress
                  # Grab all .cy.ts files in e2e/
                  files=$(ls e2e/*.cy.ts || true)

                  # If no files exist, handle that gracefully:
                  if [ -z "$files" ]; then
                    echo "chunks=[]" >> "$GITHUB_OUTPUT"
                    exit 0
                  fi

                  # 1. Chunk these filenames in groups of 2, then join each group with commas
                  chunked=$(echo "$files" | xargs -n2 | sed 's/ /,/g')

                  # 2. Convert each line into a JSON string, then produce a SINGLE-LINE JSON array
                  #    Use `-c` for "compact" (no extra newlines).
                  chunk_array=$(echo "$chunked" | jq -R . | jq -s -c .)

                  # 3. Escape special characters for GitHub output:
                  chunk_array="${chunk_array//'%'/'%25'}"
                  chunk_array="${chunk_array//$'\n'/'%0A'}"
                  chunk_array="${chunk_array//$'\r'/'%0D'}"

                  # 4. Finally, write to GITHUB_OUTPUT in valid "key=value" form
                  echo "chunks=$chunk_array" >> "$GITHUB_OUTPUT"

    container:
        name: Build and cache container image
        # run these on 4, if they're RAM constrained the FE build will fail randomly
        runs-on: depot-ubuntu-latest-4
        timeout-minutes: 60
        needs: [changes]
        permissions:
            contents: read
            id-token: write # allow issuing OIDC tokens for this workflow run
        outputs:
            tag: ${{ steps.build.outputs.tag }}
            build-id: ${{ steps.build.outputs.build-id }}
        steps:
            - name: Checkout
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3
            - name: Build the Docker image with Depot
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              # Build the container image in preparation for the E2E tests
              uses: ./.github/actions/build-n-cache-image
              id: build
              with:
                  save: true
                  actions-id-token-request-url: ${{ env.ACTIONS_ID_TOKEN_REQUEST_URL }}
                  no-cache: ${{ contains(github.event.pull_request.labels.*.name, 'no-depot-docker-cache') }}

    cypress:
        name: Cypress E2E tests (${{ strategy.job-index }})
        runs-on: ubuntu-24.04
        timeout-minutes: 60
        needs: [chunks, changes, container]
        permissions:
            id-token: write # allow issuing OIDC tokens for this workflow run

        strategy:
            # when one test fails, DO NOT cancel the other
            # containers, as there may be other spec failures
            # we want to know about.
            fail-fast: false
            matrix:
                chunk: ${{ fromJson(needs.chunks.outputs.chunks) }}

        steps:
            - name: Checkout
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3

            - name: Install pnpm
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: pnpm/action-setup@a7487c7e89a18df4991f7f222e4898a00d66ddda # v4

            - name: Set up Node.js
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: actions/setup-node@1d0ff469b7ec7b3cb9d8673fde0c81c44821de2a # v4
              with:
                  node-version: 18.12.1
                  cache: 'pnpm'

            - name: Get pnpm cache directory path
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              id: pnpm-cache-dir
              run: echo "PNPM_STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

            - name: Get cypress cache directory path
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              id: cypress-cache-dir
              run: echo "CYPRESS_BIN_PATH=$(npx cypress cache path)" >> $GITHUB_OUTPUT

            - uses: actions/cache@d4323d4df104b026a6aa633fdb11d772146be0bf # v4
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              id: pnpm-cache
              with:
                  path: |
                      ${{ steps.pnpm-cache-dir.outputs.PNPM_STORE_PATH }}
                      ${{ steps.cypress-cache-dir.outputs.CYPRESS_BIN_PATH }}
                  key: ${{ runner.os }}-pnpm-cypress-${{ hashFiles('**/pnpm-lock.yaml') }}
                  restore-keys: |
                      ${{ runner.os }}-pnpm-cypress-

            - name: Install package.json dependencies with pnpm
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              run: pnpm --filter=@posthog/cypress... install --frozen-lockfile

            - name: Prepare cypress
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              run: bin/turbo --filter=@posthog/cypress prepare

            - name: Stop/Start stack with Docker Compose
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              run: |
                  docker compose -f docker-compose.dev.yml down
                  docker compose -f docker-compose.dev.yml up -d

            - name: Wait for ClickHouse
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              run: ./bin/check_kafka_clickhouse_up

            - name: Install Depot CLI
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: depot/setup-action@b0b1ea4f69e92ebf5dea3f8713a1b0c37b2126a5 # v1

            - name: Get Docker image cached in Depot
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: depot/pull-action@8a922bdade29cf5facf3a13020cccd3b7a8127c2 # v1
              with:
                  build-id: ${{ needs.container.outputs.build-id }}
                  tags: ${{ needs.container.outputs.tag }}

            - name: Write .env # This step intentionally has no if, so that GH always considers the action as having run
              run: |
                  cat <<EOT >> .env
                  SECRET_KEY=6b01eee4f945ca25045b5aab440b953461faf08693a9abbf1166dc7c6b9772da
                  REDIS_URL=redis://localhost
                  DATABASE_URL=postgres://posthog:posthog@localhost:5432/posthog
                  KAFKA_HOSTS=kafka:9092
                  DISABLE_SECURE_SSL_REDIRECT=1
                  SECURE_COOKIES=0
                  OPT_OUT_CAPTURE=0
                  E2E_TESTING=1
                  SKIP_SERVICE_VERSION_REQUIREMENTS=1
                  EMAIL_HOST=email.test.posthog.net
                  SITE_URL=http://localhost:8000
                  NO_RESTART_LOOP=1
                  CLICKHOUSE_SECURE=0
                  OBJECT_STORAGE_ENABLED=1
                  OBJECT_STORAGE_ENDPOINT=http://localhost:19000
                  OBJECT_STORAGE_ACCESS_KEY_ID=object_storage_root_user
                  OBJECT_STORAGE_SECRET_ACCESS_KEY=object_storage_root_password
                  GITHUB_ACTION_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  CELERY_METRICS_PORT=8999
                  CLOUD_DEPLOYMENT=E2E
                  ENCRYPTION_SALT_KEYS=00beef0000beef0000beef0000beef00
                  EOT

            - name: Start PostHog
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              run: |
                  mkdir -p /tmp/logs

                  echo "Starting PostHog using the container image ${{ needs.container.outputs.tag }}"
                  DOCKER_RUN="docker run --rm --network host --add-host kafka:127.0.0.1 --add-host clickhouse:127.0.0.1 --env-file .env ${{ needs.container.outputs.tag }}"

                  $DOCKER_RUN ./bin/migrate
                  $DOCKER_RUN python manage.py setup_dev

                  # only starts the plugin server so that the "wait for PostHog" step passes
                  $DOCKER_RUN ./bin/docker-worker &> /tmp/logs/worker.txt &
                  $DOCKER_RUN ./bin/docker-server &> /tmp/logs/server.txt &

            - name: Wait for PostHog
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              # this action might be abandoned - but v1 doesn't point to latest of v1 (which it should)
              # so pointing to v1.1.0 to remove warnings about node version with v1
              # todo check https://github.com/iFaxity/wait-on-action/releases for new releases
              uses: iFaxity/wait-on-action@a7d13170ec542bdca4ef8ac4b15e9c6aa00a6866 # v1.2.1
              timeout-minutes: 5
              with:
                  verbose: true
                  log: true
                  resource: http://localhost:8000

            - name: Cypress run
              # these are required checks so, we can't skip entire sections
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: cypress-io/github-action@108b8684ae52e735ff7891524cbffbcd4be5b19f # v6
              with:
                  install-command: 'pnpm --filter=@posthog/cypress... install --frozen-lockfile'
                  command: 'pnpm --filter=@posthog/cypress exec cypress run --config-file cypress.e2e.config.ts --spec ${{ matrix.chunk }} --headed --no-runner-ui'
                  # We were seeing suprising crashes in headless mode
                  # See https://github.com/cypress-io/cypress/issues/28893#issuecomment-1956480875
              env:
                  E2E_TESTING: 1
                  OPT_OUT_CAPTURE: 0
                  GITHUB_ACTION_RUN_URL: '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}'

            - name: Archive test screenshots
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: screenshots-${{ strategy.job-index }}
                  path: cypress/screenshots
              if: ${{ failure() }}

            - name: Archive test downloads
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: downloads-${{ strategy.job-index }}
                  path: cypress/downloads
              if: ${{ failure() }}

            - name: Archive test videos
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: videos-${{ strategy.job-index }}
                  path: cypress/videos
              if: ${{ failure() }}

            - name: Archive accessibility violations
              if: needs.changes.outputs.shouldTriggerCypress == 'true'
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: accessibility-violations-${{ strategy.job-index }}
                  path: '**/a11y/'
                  if-no-files-found: 'ignore'

            - name: Show logs on failure
              # use artefact here, as I think the output will be too large for display in an action
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: logs-${{ strategy.job-index }}
                  path: /tmp/logs
              if: ${{ failure() }}

    calculate-running-time:
        name: Calculate running time
        runs-on: ubuntu-24.04
        needs: [cypress]
        if: needs.changes.outputs.shouldTriggerCypress == 'true' &&
            github.event.pull_request.head.repo.full_name == 'PostHog/posthog'
        steps:
            - name: Calculate running time
              run: |
                  gh auth login --with-token < <(echo ${{ secrets.GITHUB_TOKEN }})
                  run_id=${GITHUB_RUN_ID}
                  repo=${GITHUB_REPOSITORY}
                  run_info=$(gh api repos/${repo}/actions/runs/${run_id})
                  echo run_info: ${run_info}
                  # name is the name of the workflow file
                  # run_started_at is the start time of the workflow
                  # we want to get the number of seconds between the start time and now
                  name=$(echo ${run_info} | jq -r '.name')
                  run_url=$(echo ${run_info} | jq -r '.url')
                  run_started_at=$(echo ${run_info} | jq -r '.run_started_at')
                  run_attempt=$(echo ${run_info} | jq -r '.run_attempt')
                  start_seconds=$(date -d "${run_started_at}" +%s)
                  now_seconds=$(date +%s)
                  duration=$((now_seconds-start_seconds))
                  echo running_time_duration_seconds=${duration} >> $GITHUB_ENV
                  echo running_time_run_url=${run_url} >> $GITHUB_ENV
                  echo running_time_run_attempt=${run_attempt} >> $GITHUB_ENV
                  echo running_time_run_id=${run_id} >> $GITHUB_ENV
                  echo running_time_run_started_at=${run_started_at} >> $GITHUB_ENV

            - name: Capture running time to PostHog
              if: github.event.pull_request.head.repo.full_name == 'PostHog/posthog'
              uses: PostHog/posthog-github-action@v0.1
              with:
                  posthog-token: ${{secrets.POSTHOG_API_TOKEN}}
                  event: 'posthog-ci-running-time'
                  properties: '{"duration_seconds": ${{ env.running_time_duration_seconds }}, "run_url": "${{ env.running_time_run_url }}", "run_attempt": "${{ env.running_time_run_attempt }}", "run_id": "${{ env.running_time_run_id }}", "run_started_at": "${{ env.running_time_run_started_at }}"}'

#
# This workflow runs CI E2E tests with Playwright.
#
# It relies on the container image built by 'container-images-ci.yml'.
#
name: E2E CI Playwright
on:
    pull_request:
    workflow_dispatch:
    push:
        branches:
            - master

permissions:
    contents: write
    pull-requests: write

env:
    SECRET_KEY: '6b01eee4f945ca25045b5aab440b953461faf08693a9abbf1166dc7c6b9772da' # unsafe - for testing only
    REDIS_URL: redis://localhost
    DATABASE_URL: postgres://posthog:posthog@localhost:5432/posthog_e2e_test
    PERSONS_DB_WRITER_URL: postgres://posthog:posthog@localhost:5432/posthog_persons_e2e_test
    KAFKA_HOSTS: kafka:9092
    DISABLE_SECURE_SSL_REDIRECT: 1
    SECURE_COOKIES: 0
    OPT_OUT_CAPTURE: 0
    E2E_TESTING: 1
    SKIP_SERVICE_VERSION_REQUIREMENTS: 1
    EMAIL_HOST: email.test.posthog.net
    SITE_URL: http://localhost:8000
    NO_RESTART_LOOP: 1
    OBJECT_STORAGE_ENABLED: 1
    OBJECT_STORAGE_ENDPOINT: http://localhost:19000
    OBJECT_STORAGE_ACCESS_KEY_ID: object_storage_root_user
    OBJECT_STORAGE_SECRET_ACCESS_KEY: object_storage_root_password
    GITHUB_ACTION_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
    CELERY_METRICS_PORT: 8999
    CLOUD_DEPLOYMENT: E2E
    CLICKHOUSE_HOST: 'localhost'
    CLICKHOUSE_SECURE: 'False'
    CLICKHOUSE_VERIFY: 'False'
    CLICKHOUSE_DATABASE: posthog_test
    PGHOST: localhost
    PGUSER: posthog
    PGPASSWORD: posthog
    PGPORT: 5432
    # this is a fake key so this workflow can run for external contributors as they do not have access to secrets (that we don't need here)
    OIDC_RSA_PRIVATE_KEY: ${{ vars.OIDC_RSA_FAKE_PRIVATE_KEY }}
    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
    GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
    INKEEP_API_KEY: ${{ secrets.INKEEP_API_KEY }}
    AZURE_INFERENCE_CREDENTIAL: ${{ secrets.AZURE_INFERENCE_CREDENTIAL }}
    AZURE_INFERENCE_ENDPOINT: ${{ secrets.AZURE_INFERENCE_ENDPOINT }}

concurrency:
    group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
    # Cancel in-progress runs on PRs when new commits are pushed
    # SHA verification ensures we don't commit stale snapshots if runs aren't cancelled in time
    cancel-in-progress: ${{ github.event_name == 'pull_request' }}

jobs:
    changes:
        runs-on: ubuntu-latest
        timeout-minutes: 5
        # Only run on PRs from the same repo (not forks) or on master push
        if: github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository
        name: Determine need to run E2E checks
        # Set job outputs to values from filter step
        outputs:
            shouldRun: ${{ steps.changes.outputs.shouldRun || 'true' }}
        steps:
            # For pull requests it's not necessary to check out the code
            - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2
              id: changes
              if: github.event_name != 'push' # Run all tests on master push
              with:
                  filters: |
                      shouldRun:
                        # Avoid running E2E tests for irrelevant changes
                        # NOTE: we are at risk of missing a dependency here. We could make
                        # the dependencies more clear if we separated the backend/frontend
                        # code completely
                        - 'ee/**'
                        - 'posthog/!(temporal/**)/**'
                        - 'bin/*'
                        - frontend/**/*
                        - requirements.txt
                        - requirements-dev.txt
                        - package.json
                        - pnpm-lock.yaml
                        # Make sure we run if someone is explicitly changes the workflow
                        - .github/workflows/ci-e2e-playwright.yml
                        - .github/actions/build-n-cache-image/action.yml
                        # We use docker compose for tests, make sure we rerun on
                        # changes to docker-compose.dev.yml e.g. dependency
                        # version changes
                        - docker-compose.dev.yml
                        - Dockerfile
                        - playwright/**

    detect-snapshot-mode:
        name: Detect snapshot mode
        runs-on: ubuntu-latest
        needs: [changes]
        if: needs.changes.outputs.shouldRun == 'true'
        outputs:
            mode: ${{ steps.detect.outputs.mode }}
        steps:
            - name: Detect mode
              id: detect
              run: |
                  if [ "${{ github.event.pull_request.head.repo.full_name }}" != "${{ github.repository }}" ]; then
                    echo "mode=check" >> $GITHUB_OUTPUT
                    echo "Fork detected - running in CHECK mode (no commits allowed)"
                  else
                    AUTHOR="${{ github.actor }}"
                    echo "Workflow triggered by: $AUTHOR"
                    if [[ "$AUTHOR" == *"github-actions"* ]] || [[ "$AUTHOR" == *"[bot]"* ]] || [[ "$AUTHOR" == "posthog-bot" ]]; then
                      echo "mode=check" >> $GITHUB_OUTPUT
                      echo "::notice::ðŸ” Running in CHECK mode - snapshots must match exactly"
                    else
                      echo "mode=update" >> $GITHUB_OUTPUT
                      echo "::notice::ðŸ”„ Running in UPDATE mode - snapshots can be updated"
                    fi
                  fi

    playwright:
        name: Playwright E2E tests
        needs: [changes, detect-snapshot-mode]
        if: needs.changes.outputs.shouldRun == 'true'
        runs-on: depot-ubuntu-latest-16
        timeout-minutes: 30
        steps:
            - uses: actions/checkout@v6
              with:
                  ref: ${{ github.event.pull_request.head.sha || github.sha }}
                  repository: ${{ github.event.pull_request.head.repo.full_name || github.repository }}
                  clean: false
            - name: Clean up data directories with container permissions
              run: |
                  # Use docker to clean up files created by containers
                  [ -d "data" ] && docker run --rm -v "$(pwd)/data:/data" alpine sh -c "rm -rf /data/seaweedfs /data/minio" || true
              continue-on-error: true

            - name: Stop/Start stack with Docker Compose
              shell: bash
              run: |
                  export CLICKHOUSE_SERVER_IMAGE=clickhouse/clickhouse-server:25.8.12.129
                  export DOCKER_REGISTRY_PREFIX="us-east1-docker.pkg.dev/posthog-301601/mirror/"
                  cp posthog/user_scripts/latest_user_defined_function.xml docker/clickhouse/user_defined_function.xml

                  (
                    max_attempts=3
                    attempt=1
                    delay=5

                    while [ $attempt -le $max_attempts ]; do
                        echo "Attempt $attempt of $max_attempts to start stack..."

                        if docker compose -f docker-compose.dev.yml down && \
                          docker compose -f docker-compose.dev.yml up -d; then
                            echo "Stack started successfully"
                            exit 0
                        fi

                        echo "Failed to start stack on attempt $attempt"

                        if [ $attempt -lt $max_attempts ]; then
                            sleep_time=$((delay * 2 ** (attempt - 1)))
                            echo "Waiting ${sleep_time} seconds before retry..."
                            sleep $sleep_time
                        fi

                        attempt=$((attempt + 1))
                    done

                    echo "Failed to start stack after $max_attempts attempts"
                    exit 1
                  ) &

            - name: Add Kafka and ClickHouse to /etc/hosts
              shell: bash
              run: echo "127.0.0.1 kafka clickhouse" | sudo tee -a /etc/hosts

            - name: Set up Python
              uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
              with:
                  python-version: 3.12.12

            - name: Install uv
              id: setup-uv
              uses: astral-sh/setup-uv@61cb8a9741eeb8a550a1b8544337180c0fc8476b # v7.2.0
              with:
                  enable-cache: true
                  version: 0.9.9

            - name: Determine if hogql-parser has changed compared to master
              shell: bash
              id: hogql-parser-diff
              run: |
                  git fetch --no-tags --prune --depth=1 origin master
                  changed=$(git diff --quiet HEAD origin/master -- common/hogql_parser/ && echo "false" || echo "true")
                  echo "changed=$changed" >> $GITHUB_OUTPUT

            - name: Install SAML (python3-saml) dependencies
              if: steps.setup-uv.outputs.cache-hit != 'true'
              shell: bash
              run: |
                  sudo apt-get update && sudo apt-get install libxml2-dev libxmlsec1-dev libxmlsec1-openssl

            - name: Install pnpm
              uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4.2.0

            - name: Set up Node.js
              uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
              with:
                  node-version: 22.22.0
                  cache: pnpm

            # tests would intermittently fail in GH actions
            # with exit code 134 _after passing_ all tests
            # this appears to fix it
            # absolute wild tbh https://stackoverflow.com/a/75503402
            - uses: tlambert03/setup-qt-libs@19e4ef2d781d81f5f067182e228b54ec90d23b76 # v1.8

            - name: Install plugin_transpiler
              shell: bash
              run: |
                  pnpm --filter=@posthog/plugin-transpiler... install --frozen-lockfile
                  bin/turbo --filter=@posthog/plugin-transpiler build

            - name: Install Python dependencies
              shell: bash
              run: |
                  UV_PROJECT_ENVIRONMENT=$pythonLocation uv sync --frozen --dev

            - name: Install the working version of hogql-parser
              if: needs.changes.outputs.shouldRun == 'true' && steps.hogql-parser-diff.outputs.changed == 'true'
              shell: bash
              # This is not cached currently, as it's important to build the current HEAD version of hogql-parser if it has
              # changed (requirements.txt has the already-published version)
              run: |
                  sudo apt-get install libboost-all-dev unzip cmake curl uuid pkg-config
                  curl https://www.antlr.org/download/antlr4-cpp-runtime-4.13.1-source.zip --output antlr4-source.zip
                  # Check that the downloaded archive is the expected runtime - a security measure
                  anltr_known_md5sum="c875c148991aacd043f733827644a76f"
                  antlr_found_ms5sum="$(md5sum antlr4-source.zip | cut -d' ' -f1)"
                  if [[ "$anltr_known_md5sum" != "$antlr_found_ms5sum" ]]; then
                      echo "Unexpected MD5 sum of antlr4-source.zip!"
                      echo "Known: $anltr_known_md5sum"
                      echo "Found: $antlr_found_ms5sum"
                      exit 64
                  fi
                  unzip antlr4-source.zip -d antlr4-source && cd antlr4-source
                  cmake .
                  DESTDIR=out make install
                  sudo cp -r out/usr/local/include/antlr4-runtime /usr/include/
                  sudo cp out/usr/local/lib/libantlr4-runtime.so* /usr/lib/
                  sudo ldconfig
                  cd ..
                  pip install ./common/hogql_parser

            - name: Set up needed files
              shell: bash
              run: |
                  mkdir -p frontend/dist
                  touch frontend/dist/index.html
                  touch frontend/dist/layout.html
                  touch frontend/dist/exporter.html
                  ./bin/download-mmdb

            - name: Install package.json dependencies with pnpm
              run: |
                  pnpm --filter=@posthog/playwright... install --frozen-lockfile
                  bin/turbo --filter=@posthog/frontend prepare

            - name: Wait for services to be available
              run: |
                  bin/check_kafka_clickhouse_up
                  bin/check_postgres_up

            - name: Build frontend
              run: |
                  pnpm --filter=@posthog/frontend... install --frozen-lockfile
                  pnpm --filter=@posthog/frontend build:products
                  pnpm --filter=@posthog/frontend build

            - name: Collect static files
              run: |
                  # KLUDGE: to get the image-bitmap-data-url-worker-*.js.map files into the dist folder
                  # KLUDGE: rrweb thinks they're alongside and the django's collectstatic fails
                  cp frontend/node_modules/@posthog/rrweb/dist/image-bitmap-data-url-worker-*.js.map frontend/dist/ && python manage.py collectstatic --noinput
            - name: Create test database
              run: |
                  createdb posthog_e2e_test || echo "Database already exists"
                  # Drop and recreate clickhouse test database
                  echo 'DROP DATABASE if exists posthog_test' | curl 'http://localhost:8123/' --data-binary @-
                  echo 'create database posthog_test' | curl 'http://localhost:8123/' --data-binary @-

            - name: Cache Rust dependencies
              uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2.8.2

            - name: Install sqlx-cli
              run: cargo install sqlx-cli --version 0.8.0 --features postgres --no-default-features --locked

            - name: Apply postgres and clickhouse migrations and setup dev
              run: |
                  python manage.py migrate_clickhouse &
                  python manage.py migrate --noinput

                  # Run Rust migrations for persons e2e test database
                  PERSONS_DATABASE_URL="postgres://posthog:posthog@localhost:5432/posthog_persons_e2e_test"
                  sqlx database create -D "$PERSONS_DATABASE_URL"
                  sqlx migrate run -D "$PERSONS_DATABASE_URL" --source rust/persons_migrations/

                  python manage.py setup_dev
                  wait

            - name: Source celery queues
              run: |
                  source ./bin/celery-queues.env
                  echo "CELERY_WORKER_QUEUES=$CELERY_WORKER_QUEUES" >> $GITHUB_ENV

            - name: Start PostHog web & Celery worker
              run: |
                  python manage.py run_autoreload_celery --type=worker &> /tmp/celery.log &
                  python -m granian --interface asgi posthog.asgi:application --host 0.0.0.0 --port 8000 --log-level debug --workers 4 &> /tmp/server.log &

            # Install Playwright browsers while we wait for PostHog to be ready
            - name: Install Playwright browsers
              run: pnpm --filter=@posthog/playwright exec playwright install chromium --with-deps

            - name: Wait for PostHog to be ready
              uses: iFaxity/wait-on-action@1fe019e0475491e9e8c4f421b6914ccc3ed8f99c # v1.2.1
              with:
                  resource: http://localhost:8000
                  timeout: 180000
                  interval: 2000
                  verbose: true

            - name: Run Playwright tests
              id: playwright-tests
              shell: bash
              # Run 6 Playwright workers against 4 granian workers
              # This balances parallelism with server capacity to avoid timeouts
              run: |
                  set +e  # Allow snapshot update retry
                  # Attempt 1: Always verify (fast path when snapshots match)
                  # Attempt 2: Update snapshots if previous failure was screenshot-related (UPDATE mode only)
                  # Note: Playwright's built-in retry (3x per test) handles test flakiness
                  echo "Attempt 1: Running Playwright tests"
                  set -o pipefail
                  pnpm --filter=@posthog/playwright exec playwright test --workers=6 2>&1 | tee /tmp/playwright-output-attempt-1.log
                  EXIT_CODE=$?
                  set +o pipefail

                  if [ $EXIT_CODE -ne 0 ]; then
                    # Check if we should retry with snapshot update
                    # Look for either "Screenshot comparison failed" or "snapshot doesn't exist" error messages
                    # Use case-insensitive match to catch variations like "Snapshot does not exist"
                    if [ "${{ needs.detect-snapshot-mode.outputs.mode }}" == "update" ] && grep -qEi "(Screenshot comparison failed|snapshot does(n't| not) exist)" /tmp/playwright-output-attempt-1.log 2>/dev/null; then
                      echo "Screenshot-related failure detected - retrying with --update-snapshots"

                      # Preserve attempt 1 artifacts
                      echo "Preserving attempt 1 artifacts..."
                      mkdir -p playwright/test-results-attempt-1 playwright/playwright-report-attempt-1
                      cp -r playwright/test-results/* playwright/test-results-attempt-1/ 2>/dev/null || true
                      cp -r playwright/playwright-report/* playwright/playwright-report-attempt-1/ 2>/dev/null || true

                      # Attempt 2: Update snapshots
                      echo "Attempt 2: Running Playwright tests with --update-snapshots"
                      set -o pipefail
                      pnpm --filter=@posthog/playwright exec playwright test --workers=6 --update-snapshots 2>&1 | tee /tmp/playwright-output-attempt-2.log
                      EXIT_CODE=$?
                      set +o pipefail

                      if [ $EXIT_CODE -ne 0 ]; then
                        echo "Playwright tests failed after 2 attempts"
                        exit 1
                      fi
                    else
                      echo "Non-screenshot failure - not retrying (Playwright already retried failed tests 3x)"
                      exit 1
                    fi
                  fi

            # Create git patch for aggregation (handles A/M/D including binary files)
            # Only run in UPDATE mode - CHECK mode doesn't update snapshots
            # Run even if tests failed, as long as snapshots may have been updated
            - name: Create screenshot patch
              id: create-patch
              if: needs.detect-snapshot-mode.outputs.mode == 'update' && (success() || failure()) && needs.changes.outputs.shouldRun == 'true' && github.event.pull_request.head.repo.full_name == github.repository
              run: |
                  # Verify we're in a git repository before running git commands
                  if ! git rev-parse --git-dir > /dev/null 2>&1; then
                    echo "Not in a git repository, skipping patch creation"
                    echo "has-changes=false" >> $GITHUB_OUTPUT
                    exit 0
                  fi

                  # Check if there are any changes (modified or untracked) in the snapshots directory
                  # Use git status --porcelain to detect both modifications and new untracked files
                  if [ -z "$(git status --porcelain playwright/__snapshots__/)" ]; then
                    echo "No screenshot changes"
                    echo "has-changes=false" >> $GITHUB_OUTPUT
                  else
                    echo "Screenshot changes detected:"
                    git status --short playwright/__snapshots__/

                    # Stage untracked files so git diff can include them in the patch
                    git add -N playwright/__snapshots__/
                    # Create binary-safe patch file
                    mkdir -p /tmp/patches
                    git diff --binary --full-index playwright/__snapshots__/ > /tmp/patches/playwright-patch.patch
                    echo "Created patch file"
                    echo "has-changes=true" >> $GITHUB_OUTPUT
                  fi

            - name: Upload screenshot patch
              if: steps.create-patch.outputs.has-changes == 'true' && (success() || failure())
              uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
              with:
                  name: playwright-patch
                  path: /tmp/patches/playwright-patch.patch
                  retention-days: 1
                  if-no-files-found: ignore

            # â”€â”€ Artifacts on failure / always â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            - name: Capture docker logs
              if: always()
              run: docker logs posthog-proxy-1 > playwright/test-results/docker-proxy.log 2>&1 || echo "No proxy container" > playwright/test-results/docker-proxy.log

            - name: Archive test artifacts
              if: always()
              uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
              with:
                  name: playwright-test-results-${{ matrix.segment }}
                  path: |
                      playwright/playwright-report/
                      playwright/playwright-report-attempt-*/
                      playwright/test-results/
                      playwright/test-results-attempt-*/
                      /tmp/celery.log
                      /tmp/server.log
                      /tmp/playwright-output-attempt-*.log
                  retention-days: 30
                  if-no-files-found: ignore

    capture-run-time:
        name: Capture run time
        runs-on: ubuntu-latest
        needs: [changes, playwright]
        if: needs.changes.outputs.shouldRun == 'true'
        steps:
            - name: Calculate run time and send to PostHog
              run: |
                  gh auth login --with-token < <(echo ${{ secrets.GITHUB_TOKEN }})
                  run_id=${GITHUB_RUN_ID}
                  repo=${GITHUB_REPOSITORY}
                  run_info=$(gh api repos/${repo}/actions/runs/${run_id})
                  echo run_info: ${run_info}
                  # name is the name of the workflow file
                  # run_started_at is the start time of the workflow
                  # we want to get the number of seconds between the start time and now
                  name=$(echo ${run_info} | jq -r '.name')
                  run_url=$(echo ${run_info} | jq -r '.url')
                  run_started_at=$(echo ${run_info} | jq -r '.run_started_at')
                  run_attempt=$(echo ${run_info} | jq -r '.run_attempt')
                  start_seconds=$(date -d "${run_started_at}" +%s)
                  now_seconds=$(date +%s)
                  duration=$((now_seconds-start_seconds))
                  echo running_time_duration_seconds=${duration} >> $GITHUB_ENV
                  echo running_time_run_url=${run_url} >> $GITHUB_ENV
                  echo running_time_run_attempt=${run_attempt} >> $GITHUB_ENV
                  echo running_time_run_id=${run_id} >> $GITHUB_ENV
                  echo running_time_run_started_at=${run_started_at} >> $GITHUB_ENV
            - name: Capture running time to PostHog
              if: github.repository == 'PostHog/posthog'
              uses: PostHog/posthog-github-action@8c42e50f2c52e002eabb9bee3f69b152ee8fc1dd # v1.0.1
              with:
                  posthog-token: ${{secrets.POSTHOG_API_TOKEN}}
                  event: 'posthog-ci-running-time'
                  properties: '{"runner": "depot", "duration_seconds": ${{ env.running_time_duration_seconds }}, "run_url": "${{ env.running_time_run_url }}", "run_attempt": "${{ env.running_time_run_attempt }}", "run_id": "${{ env.running_time_run_id }}", "run_started_at": "${{ env.running_time_run_started_at }}"}'

    # Aggregate all screenshot artifacts and commit once
    handle-screenshots:
        name: Handle screenshot changes
        runs-on: ubuntu-latest
        needs: [playwright, detect-snapshot-mode, changes]
        if: always() && needs.detect-snapshot-mode.outputs.mode == 'update' && needs.changes.outputs.shouldRun == 'true' && github.event.pull_request.head.repo.full_name == github.repository
        steps:
            # Use GitHub app token so Actions run after commiting updated snapshots
            - name: Get app token
              id: app-token
              uses: getsentry/action-github-app-token@d4b5da6c5e37703f8c3b3e43abb5705b46e159cc # v3.0.0
              with:
                  app_id: ${{ secrets.GH_APP_POSTHOG_TESTS_APP_ID }}
                  private_key: ${{ secrets.GH_APP_POSTHOG_TESTS_PRIVATE_KEY }}

            - uses: actions/checkout@v6
              with:
                  ref: ${{ github.event.pull_request.head.sha }}
                  token: ${{ steps.app-token.outputs.token || github.token }}

            - name: Download screenshot patches
              id: download-patches
              continue-on-error: true
              uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
              with:
                  pattern: playwright-patch
                  path: /tmp/screenshot-patches/
                  merge-multiple: true

            - name: Check for screenshot changes
              id: check-screenshots
              run: |
                  # Check if patches were downloaded and have content
                  if [ "${{ steps.download-patches.outcome }}" == "failure" ] || [ ! -d /tmp/screenshot-patches/ ]; then
                    echo "has-changes=false" >> $GITHUB_OUTPUT
                    echo "No screenshot patches found"
                    exit 0
                  fi

                  # Check if any patch files have content (>0 bytes)
                  PATCHES=$(find /tmp/screenshot-patches -name "*.patch" -type f -size +0c)
                  if [ -z "$PATCHES" ]; then
                    echo "has-changes=false" >> $GITHUB_OUTPUT
                    echo "Patch files empty - no screenshot changes"
                  else
                    echo "has-changes=true" >> $GITHUB_OUTPUT
                    echo "Screenshot changes detected in patches"
                  fi

            # UPDATE mode: commit the changes
            - name: Commit screenshot changes
              if: steps.check-screenshots.outputs.has-changes == 'true' && needs.detect-snapshot-mode.outputs.mode == 'update'
              uses: ./.github/actions/commit-snapshots
              with:
                  workflow-type: playwright
                  patch-path: /tmp/screenshot-patches/
                  snapshot-path: playwright/
                  commit-message: 'test(e2e): update screenshots'
                  pr-number: ${{ github.event.pull_request.number }}
                  repository: ${{ github.repository }}
                  commit-sha: ${{ github.event.pull_request.head.sha }}
                  branch-name: ${{ github.event.pull_request.head.ref }}
                  github-token: ${{ steps.app-token.outputs.token || github.token }}

    # Job to collate the status of the matrix jobs for requiring passing status
    # Must depend on handle-screenshots to prevent auto-merge before commits complete
    playwright_tests:
        needs: [playwright, handle-screenshots]
        name: Playwright tests pass
        runs-on: ubuntu-latest
        if: always()
        steps:
            - name: Check matrix outcome
              run: |
                  # Check playwright matrix result
                  if [[ "${{ needs.playwright.result }}" != "success" && "${{ needs.playwright.result }}" != "skipped" ]]; then
                    echo "One or more jobs in the Playwright test matrix failed."
                    exit 1
                  fi

                  # Check handle-screenshots result (OK if skipped, but fail if it failed)
                  if [[ "${{ needs.handle-screenshots.result }}" == "failure" ]]; then
                    echo "Screenshot commit job failed."
                    exit 1
                  fi

                  echo "All jobs passed or were skipped successfully."

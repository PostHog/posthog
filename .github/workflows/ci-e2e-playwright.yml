#
# This workflow runs CI E2E tests with Playwright.
#
# It relies on the container image built by 'container-images-ci.yml'.
#
name: E2E CI Playwright
on:
    pull_request:

env:
    SECRET_KEY: '6b01eee4f945ca25045b5aab440b953461faf08693a9abbf1166dc7c6b9772da' # unsafe - for testing only
    REDIS_URL: redis://localhost
    DATABASE_URL: postgres://posthog:posthog@localhost:5432/posthog_e2e_test
    KAFKA_HOSTS: kafka:9092
    DISABLE_SECURE_SSL_REDIRECT: 1
    SECURE_COOKIES: 0
    OPT_OUT_CAPTURE: 0
    E2E_TESTING: 1
    SKIP_SERVICE_VERSION_REQUIREMENTS: 1
    EMAIL_HOST: email.test.posthog.net
    SITE_URL: http://localhost:8080
    NO_RESTART_LOOP: 1
    OBJECT_STORAGE_ENABLED: 1
    OBJECT_STORAGE_ENDPOINT: http://localhost:19000
    OBJECT_STORAGE_ACCESS_KEY_ID: object_storage_root_user
    OBJECT_STORAGE_SECRET_ACCESS_KEY: object_storage_root_password
    GITHUB_ACTION_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
    CELERY_METRICS_PORT: 8999
    CLOUD_DEPLOYMENT: E2E
    CLICKHOUSE_HOST: 'localhost'
    CLICKHOUSE_SECURE: 'False'
    CLICKHOUSE_VERIFY: 'False'
    CLICKHOUSE_DATABASE: posthog_test
    CYPRESS_BASE_URL: http://localhost:8080
    PGHOST: localhost
    PGUSER: posthog
    PGPASSWORD: posthog
    PGPORT: 5432

concurrency:
    group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
    cancel-in-progress: true

jobs:
    changes:
        runs-on: ubuntu-latest
        timeout-minutes: 5
        if: github.event.pull_request.head.repo.full_name == github.repository
        name: Determine need to run E2E checks
        # Set job outputs to values from filter step
        outputs:
            shouldRun: ${{ steps.changes.outputs.shouldRun }}
        steps:
            # For pull requests it's not necessary to check out the code
            - uses: dorny/paths-filter@4512585405083f25c027a35db413c2b3b9006d50 # v2
              id: changes
              with:
                  filters: |
                      shouldRun:
                        # Avoid running E2E tests for irrelevant changes
                        # NOTE: we are at risk of missing a dependency here. We could make
                        # the dependencies more clear if we separated the backend/frontend
                        # code completely
                        - 'ee/**'
                        - 'posthog/!(temporal/**)/**'
                        - 'bin/*'
                        - frontend/**/*
                        - requirements.txt
                        - requirements-dev.txt
                        - package.json
                        - pnpm-lock.yaml
                        # Make sure we run if someone is explicitly changes the workflow
                        - .github/workflows/ci-e2e-playwright.yml
                        - .github/actions/build-n-cache-image/action.yml
                        # We use docker compose for tests, make sure we rerun on
                        # changes to docker-compose.dev.yml e.g. dependency
                        # version changes
                        - docker-compose.dev.yml
                        - Dockerfile
                        - playwright/**

    playwright:
        name: Playwright E2E tests (${{ matrix.shard }}/3)
        needs: [changes]
        if: needs.changes.outputs.shouldRun == 'true'
        runs-on: depot-ubuntu-latest-arm-4
        timeout-minutes: 30
        strategy:
            fail-fast: false
            matrix:
                clickhouse-server-image: ['clickhouse/clickhouse-server:24.8.7.41']
                shard: [1, 2, 3]
        permissions:
            id-token: write
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

            - name: Stop/Start stack with Docker Compose
              shell: bash
              run: |
                  export CLICKHOUSE_SERVER_IMAGE=${{ matrix.clickhouse-server-image }}
                  export DOCKER_REGISTRY_PREFIX="us-east1-docker.pkg.dev/posthog-301601/mirror/"
                  cp posthog/user_scripts/latest_user_defined_function.xml docker/clickhouse/user_defined_function.xml

                  max_attempts=3
                  attempt=1
                  delay=5

                  while [ $attempt -le $max_attempts ]; do
                      echo "Attempt $attempt of $max_attempts to start stack..."
                      
                      if docker compose -f docker-compose.dev.yml down && \
                        docker compose -f docker-compose.dev.yml up -d; then
                          echo "Stack started successfully"
                          exit 0
                      fi
                      
                      echo "Failed to start stack on attempt $attempt"
                      
                      if [ $attempt -lt $max_attempts ]; then
                          sleep_time=$((delay * 2 ** (attempt - 1)))
                          echo "Waiting ${sleep_time} seconds before retry..."
                          sleep $sleep_time
                      fi
                      
                      attempt=$((attempt + 1))
                  done

                  echo "Failed to start stack after $max_attempts attempts"
                  exit 1

            - name: Add Kafka and ClickHouse to /etc/hosts
              run: echo "127.0.0.1 kafka clickhouse" | sudo tee -a /etc/hosts

            - name: Set up Python
              uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38 # v5
              with:
                  python-version: 3.11.9
                  token: ${{ secrets.POSTHOG_BOT_GITHUB_TOKEN }}

            - name: Install uv
              uses: astral-sh/setup-uv@0c5e2b8115b80b4c7c5ddf6ffdd634974642d182 # v5.4.1
              with:
                  enable-cache: false

            - name: Determine if hogql-parser has changed compared to master
              shell: bash
              id: hogql-parser-diff
              run: |
                  git fetch --no-tags --prune --depth=1 origin master
                  changed=$(git diff --quiet HEAD origin/master -- common/hogql_parser/ && echo "false" || echo "true")
                  echo "changed=$changed" >> $GITHUB_OUTPUT

            - name: Install SAML (python3-saml) dependencies
              run: |
                  sudo apt-get update
                  sudo apt-get install libxml2-dev libxmlsec1-dev libxmlsec1-openssl

            - name: Install pnpm
              uses: pnpm/action-setup@a7487c7e89a18df4991f7f222e4898a00d66ddda # v4

            - name: Set up Node.js
              uses: actions/setup-node@1a4442cacd436585916779262731d5b162bc6ec7 # v3
              with:
                  node-version: 18.12.1
                  cache: pnpm

            # tests would intermittently fail in GH actions
            # with exit code 134 _after passing_ all tests
            # this appears to fix it
            # absolute wild tbh https://stackoverflow.com/a/75503402
            - uses: tlambert03/setup-qt-libs@19e4ef2d781d81f5f067182e228b54ec90d23b76 # v1

            - name: Install plugin_transpiler
              shell: bash
              run: |
                  pnpm --filter=@posthog/plugin-transpiler... install --frozen-lockfile
                  bin/turbo --filter=@posthog/plugin-transpiler build

            - name: Install Python dependencies
              shell: bash
              run: |
                  UV_PROJECT_ENVIRONMENT=$pythonLocation uv sync --frozen --dev

            - name: Install the working version of hogql-parser
              if: ${{ steps.hogql-parser-diff.outputs.changed == 'true' }}
              shell: bash
              # This is not cached currently, as it's important to build the current HEAD version of hogql-parser if it has
              # changed (requirements.txt has the already-published version)
              run: |
                  sudo apt-get install libboost-all-dev unzip cmake curl uuid pkg-config
                  curl https://www.antlr.org/download/antlr4-cpp-runtime-4.13.1-source.zip --output antlr4-source.zip
                  # Check that the downloaded archive is the expected runtime - a security measure
                  anltr_known_md5sum="c875c148991aacd043f733827644a76f"
                  antlr_found_ms5sum="$(md5sum antlr4-source.zip | cut -d' ' -f1)"
                  if [[ "$anltr_known_md5sum" != "$antlr_found_ms5sum" ]]; then
                      echo "Unexpected MD5 sum of antlr4-source.zip!"
                      echo "Known: $anltr_known_md5sum"
                      echo "Found: $antlr_found_ms5sum"
                      exit 64
                  fi
                  unzip antlr4-source.zip -d antlr4-source && cd antlr4-source
                  cmake .
                  DESTDIR=out make install
                  sudo cp -r out/usr/local/include/antlr4-runtime /usr/include/
                  sudo cp out/usr/local/lib/libantlr4-runtime.so* /usr/lib/
                  sudo ldconfig
                  cd ..
                  uv pip install ./common/hogql_parser

            - name: Get pnpm cache directory path
              id: pnpm-cache-dir
              run: echo "PNPM_STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

            - uses: actions/cache@d4323d4df104b026a6aa633fdb11d772146be0bf # v4
              id: pnpm-cache
              with:
                  path: ${{ steps.pnpm-cache-dir.outputs.PNPM_STORE_PATH }}
                  key: ${{ runner.os }}-pnpm-cypress-${{ hashFiles('pnpm-lock.yaml') }}
                  restore-keys: ${{ runner.os }}-pnpm-cypress-

            - name: Install package.json dependencies with pnpm
              run: |
                  pnpm --filter=@posthog/playwright... install --frozen-lockfile
                  bin/turbo --filter=@posthog/frontend prepare

            - name: Install Playwright browsers
              run: pnpm --filter=@posthog/playwright exec playwright install --with-deps

            # Pre-build product bundles needed by UI
            - name: Build frontend
              run: |
                  pnpm --filter=@posthog/frontend build:products
                  pnpm --filter=@posthog/frontend build

            - name: Wait for ClickHouse & Kafka
              run: ./bin/check_kafka_clickhouse_up

            - name: Create test database
              run: |
                  createdb posthog_e2e_test || echo "Database already exists"
                  # Drop and recreate clickhouse test database
                  echo 'DROP DATABASE if exists posthog_test' | curl 'http://localhost:8123/' --data-binary @-
                  echo 'create database posthog_test' | curl 'http://localhost:8123/' --data-binary @-

            - name: Apply postgres migrations
              run: python manage.py migrate --noinput

            - name: Apply clickhouse migrations
              run: python manage.py migrate_clickhouse

            - name: Seed dev data
              run: python manage.py setup_dev

            - name: Source celery queues
              run: |
                  source ./bin/celery-queues.env
                  echo "CELERY_WORKER_QUEUES=$CELERY_WORKER_QUEUES" >> $GITHUB_ENV

            # Launch PostHog web & worker in the background
            - name: Start PostHog web & Celery worker
              run: |
                  python manage.py run_autoreload_celery --type=worker &> /tmp/celery.log &
                  python manage.py runserver 8080 &> /tmp/server.log &

            - name: Wait for PostHog to be ready
              uses: iFaxity/wait-on-action@1fe019e0475491e9e8c4f421b6914ccc3ed8f99c # v1.2.1
              with:
                  resource: http://localhost:8080
                  timeout: 180000
                  interval: 2000
                  verbose: true

            - name: Run Playwright tests
              env:
                  START_PLAYWRIGHT: '1'
              run: pnpm --filter=@posthog/playwright exec playwright test --shard=${{ matrix.shard }}/3

            # ── Artifacts on failure / always ─────────────────────────────────────
            - name: Show celery logs
              if: always()
              run: cat /tmp/celery.log
            - name: Show server logs
              if: always()
              run: cat /tmp/server.log

            - name: Show server logs
              if: always()
              run: |
                  docker ps
                  docker logs posthog-proxy-1

            - name: Archive Playwright report on failure
              if: failure()
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: playwright-report-shard-${{ matrix.shard }}
                  path: playwright/playwright-report/
                  retention-days: 30

            - name: Archive screenshots
              if: always()
              uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # v4
              with:
                  name: playwright-screenshots-shard-${{ matrix.shard }}
                  path: playwright/test-results
                  retention-days: 30

    capture-run-time:
        name: Capture run time
        runs-on: ubuntu-latest
        needs: [changes, playwright]
        if: needs.changes.outputs.shouldRun == 'true'
        steps:
            - name: Calculate run time and send to PostHog
              run: |
                  gh auth login --with-token < <(echo ${{ secrets.GITHUB_TOKEN }})
                  run_id=${GITHUB_RUN_ID}
                  repo=${GITHUB_REPOSITORY}
                  run_info=$(gh api repos/${repo}/actions/runs/${run_id})
                  echo run_info: ${run_info}
                  # name is the name of the workflow file
                  # run_started_at is the start time of the workflow
                  # we want to get the number of seconds between the start time and now
                  name=$(echo ${run_info} | jq -r '.name')
                  run_url=$(echo ${run_info} | jq -r '.url')
                  run_started_at=$(echo ${run_info} | jq -r '.run_started_at')
                  run_attempt=$(echo ${run_info} | jq -r '.run_attempt')
                  start_seconds=$(date -d "${run_started_at}" +%s)
                  now_seconds=$(date +%s)
                  duration=$((now_seconds-start_seconds))
                  echo running_time_duration_seconds=${duration} >> $GITHUB_ENV
                  echo running_time_run_url=${run_url} >> $GITHUB_ENV
                  echo running_time_run_attempt=${run_attempt} >> $GITHUB_ENV
                  echo running_time_run_id=${run_id} >> $GITHUB_ENV
                  echo running_time_run_started_at=${run_started_at} >> $GITHUB_ENV
            - name: Capture running time to PostHog
              if: github.repository == 'PostHog/posthog'
              uses: PostHog/posthog-github-action@v0.1
              with:
                  posthog-token: ${{secrets.POSTHOG_API_TOKEN}}
                  event: 'posthog-ci-running-time'
                  properties: '{"runner": "depot", "duration_seconds": ${{ env.running_time_duration_seconds }}, "run_url": "${{ env.running_time_run_url }}", "run_attempt": "${{ env.running_time_run_attempt }}", "run_id": "${{ env.running_time_run_id }}", "run_started_at": "${{ env.running_time_run_started_at }}"}'

    posthog-analytics:
        name: PostHog CI analytics
        if: always() && needs.changes.outputs.shouldRun == 'true'
        needs: [capture-run-time] # last job in this workflow
        runs-on: ubuntu-latest
        steps:
            - name: Checkout
              uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3
            - uses: ./.github/actions/ci-analytics
              with:
                  posthog-api-key: ${{ secrets.CI_ANALYTICS_TOKEN }}

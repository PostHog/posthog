name: Backend CI - Update test timing

on:
    workflow_dispatch:
        inputs:
            run_id:
                description: 'CI run ID to collect timing data from (leave empty to use latest successful run)'
                required: false
                type: string
    schedule:
        # Run weekly on Sunday at 3am UTC
        - cron: '0 3 * * 0'

permissions:
    contents: write
    actions: read
    pull-requests: write

jobs:
    collect-and-merge:
        name: Collect timing data from CI artifacts
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

            - name: Find CI run to use
              id: find-run
              env:
                  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
                  INPUT_RUN_ID: ${{ inputs.run_id }}
              run: |
                  if [ -n "$INPUT_RUN_ID" ]; then
                      echo "run_id=$INPUT_RUN_ID" >> $GITHUB_OUTPUT
                      echo "Using provided CI run: $INPUT_RUN_ID"
                      exit 0
                  fi

                  # Find a recent successful ci-backend.yml run with timing artifacts
                  # Most runs skip tests due to path filtering (~20 sec), so filter by duration first
                  # Runs that actually execute tests take 15+ minutes
                  echo "Searching for CI run with timing artifacts..."

                  # Get runs that took more than 5 minutes (300 seconds) - likely ran tests
                  run_id=$(gh api "repos/${{ github.repository }}/actions/workflows/ci-backend.yml/runs?status=success&per_page=100" \
                      --jq '.workflow_runs[] | select(
                          (.updated_at | fromdateiso8601) - (.run_started_at | fromdateiso8601) > 300
                      ) | .id' | head -5 | \
                      while read id; do
                          count=$(gh api "repos/${{ github.repository }}/actions/runs/$id/artifacts?per_page=100" \
                              --jq '[.artifacts[] | select(.name | startswith("timing_data-"))] | length' 2>/dev/null)
                          echo "Run $id has $count timing artifacts" >&2
                          if [ "$count" -gt "40" ]; then
                              echo "$id"
                              break
                          fi
                      done)

                  if [ -z "$run_id" ]; then
                      echo "::error::No suitable CI run found with timing artifacts"
                      exit 1
                  fi

                  echo "run_id=$run_id" >> $GITHUB_OUTPUT
                  echo "Found CI run: $run_id"

            - name: Download timing artifacts
              env:
                  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
              run: |
                  gh run download ${{ steps.find-run.outputs.run_id }} --pattern "timing_data-*" --dir timing_artifacts

            - name: Merge and normalize timing data
              run: |
                  # Merge all timing files - later values override earlier for same keys
                  jq -s 'reduce .[] as $item ({}; . * $item)' timing_artifacts/*/.test_durations > .test_durations.raw

                  # Clean up downloaded artifacts
                  rm -rf timing_artifacts

                  # Normalize timing data to improve shard distribution:
                  # - CEILING (60s): First test in each shard gets blamed for global setup time (~240s)
                  #   which skews distribution. Cap these and replace with average.
                  # - FLOOR (0.5s): Many fast tests (0.01s) cluster at end of alphabet, causing
                  #   empty shards with duration_based_chunks algorithm.
                  python3 << 'PYEOF'
                  import json

                  CEILING = 60.0  # Tests above this are likely inflated by shard startup
                  FLOOR = 0.5     # Minimum duration to prevent fast test clustering

                  with open(".test_durations.raw") as f:
                      durations = json.load(f)

                  # Calculate average for replacement
                  values = list(durations.values())
                  avg = sum(values) / len(values)

                  # Apply ceiling and floor
                  processed = {}
                  ceiling_count = 0
                  floor_count = 0
                  for test, duration in durations.items():
                      if duration > CEILING:
                          processed[test] = avg
                          ceiling_count += 1
                      elif duration < FLOOR:
                          processed[test] = FLOOR
                          floor_count += 1
                      else:
                          processed[test] = duration

                  with open(".test_durations", "w") as f:
                      json.dump(processed, f, separators=(",", ":"), sort_keys=True)

                  print(f"Normalized timing data:")
                  print(f"  Total tests: {len(processed)}")
                  print(f"  Ceiling ({CEILING}s) applied to: {ceiling_count} tests")
                  print(f"  Floor ({FLOOR}s) applied to: {floor_count} tests")
                  PYEOF

                  rm .test_durations.raw

            - name: Check for changes
              id: check-changes
              run: |
                  if git diff --quiet .test_durations; then
                      echo "No changes to test durations"
                      echo "changed=false" >> $GITHUB_OUTPUT
                  else
                      echo "Test durations updated"
                      echo "changed=true" >> $GITHUB_OUTPUT
                      git diff --stat .test_durations
                  fi

            - name: Create Pull Request
              if: steps.check-changes.outputs.changed == 'true'
              uses: peter-evans/create-pull-request@84ae59a2cdc2258d6fa0732dd66352dddae2a412 # v7
              with:
                  token: ${{ secrets.POSTHOG_BOT_PAT }}
                  commit-message: 'chore(ci): update backend test timings'
                  title: 'chore(ci): update backend test timings'
                  body: |
                      Automated update of backend test timing data from CI run [${{ steps.find-run.outputs.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ steps.find-run.outputs.run_id }}).

                      This keeps pytest-split sharding balanced.
                  branch: chore/update-test-timings
                  delete-branch: true

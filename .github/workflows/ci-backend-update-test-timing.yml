name: Backend CI - Update test timing

on:
    workflow_dispatch:
        inputs:
            run_id:
                description: 'CI run ID to collect timing data from (leave empty to use latest successful run)'
                required: false
                type: string
    schedule:
        # Run weekly on Sunday at 3am UTC
        - cron: '0 3 * * 0'

permissions:
    contents: write
    actions: read
    pull-requests: write

jobs:
    collect-and-merge:
        name: Collect timing data from CI artifacts
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v6

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: '3.12'

            - name: Install pytest for test collection
              run: pip install pytest pytest-split

            - name: Find CI run to use
              id: find-run
              env:
                  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
                  INPUT_RUN_ID: ${{ inputs.run_id }}
              run: |
                  if [ -n "$INPUT_RUN_ID" ]; then
                      echo "run_id=$INPUT_RUN_ID" >> $GITHUB_OUTPUT
                      echo "Using provided CI run: $INPUT_RUN_ID"
                      exit 0
                  fi

                  # Find a recent successful ci-backend.yml run with timing artifacts
                  # Most runs skip tests due to path filtering (~20 sec), so filter by duration first
                  # Runs that actually execute tests take 15+ minutes
                  echo "Searching for CI run with timing artifacts..."

                  # Get runs that took more than 5 minutes (300 seconds) - likely ran tests
                  run_id=$(gh api "repos/${{ github.repository }}/actions/workflows/ci-backend.yml/runs?status=success&per_page=100" \
                      --jq '.workflow_runs[] | select(
                          (.updated_at | fromdateiso8601) - (.run_started_at | fromdateiso8601) > 300
                      ) | .id' | head -5 | \
                      while read id; do
                          count=$(gh api "repos/${{ github.repository }}/actions/runs/$id/artifacts?per_page=100" \
                              --jq '[.artifacts[] | select(.name | startswith("timing_data-"))] | length' 2>/dev/null)
                          echo "Run $id has $count timing artifacts" >&2
                          if [ "$count" -gt "40" ]; then
                              echo "$id"
                              break
                          fi
                      done)

                  if [ -z "$run_id" ]; then
                      echo "::error::No suitable CI run found with timing artifacts"
                      exit 1
                  fi

                  echo "run_id=$run_id" >> $GITHUB_OUTPUT
                  echo "Found CI run: $run_id"

            - name: Download timing artifacts
              env:
                  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
              run: |
                  gh run download ${{ steps.find-run.outputs.run_id }} --pattern "timing_data-*" --dir timing_artifacts

            - name: Optimize timing data for balanced shards
              run: |
                  # Optimize each segment separately with its own shard count, then merge
                  # --filter-existing removes stale tests that no longer exist in codebase
                  # Core: 40 shards, Temporal: 10 shards
                  python3 .github/scripts/optimize_test_durations.py timing_artifacts /tmp/core_durations \
                      --num-shards 40 --ceiling 60 --segment Core --filter-existing
                  python3 .github/scripts/optimize_test_durations.py timing_artifacts /tmp/temporal_durations \
                      --num-shards 10 --ceiling 60 --segment Temporal --filter-existing

                  # Merge into single file (Core first, then Temporal overwrites any overlaps)
                  python3 -c "
                  import json
                  with open('/tmp/core_durations') as f: durations = json.load(f)
                  with open('/tmp/temporal_durations') as f: durations.update(json.load(f))
                  with open('.test_durations', 'w') as f: json.dump(durations, f, separators=(',', ':'), sort_keys=True)
                  print(f'Merged {len(durations)} tests')
                  "
                  rm -rf timing_artifacts /tmp/core_durations /tmp/temporal_durations

            - name: Check for changes
              id: check-changes
              run: |
                  if git diff --quiet .test_durations; then
                      echo "No changes to test durations"
                      echo "changed=false" >> $GITHUB_OUTPUT
                  else
                      echo "Test durations updated"
                      echo "changed=true" >> $GITHUB_OUTPUT
                      git diff --stat .test_durations
                  fi

            - name: Create Pull Request
              if: steps.check-changes.outputs.changed == 'true'
              uses: peter-evans/create-pull-request@84ae59a2cdc2258d6fa0732dd66352dddae2a412 # v7
              with:
                  token: ${{ secrets.POSTHOG_BOT_PAT }}
                  commit-message: 'chore(ci): update backend test timings'
                  title: 'chore(ci): update backend test timings'
                  body: |
                      Automated update of backend test timing data from CI run [${{ steps.find-run.outputs.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ steps.find-run.outputs.run_id }}).

                      This keeps pytest-split sharding balanced.
                  branch: chore/update-test-timings
                  delete-branch: true

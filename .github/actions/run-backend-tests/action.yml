#
# This is a composite action that packages our backend Django tests.
# It is called by the `ci-backend.yml` job using a matrix.
#
name: Run Backend Django tests
inputs:
    python-version:
        required: true
        type: string
    clickhouse-server-image:
        required: true
        type: string
    segment:
        required: true
        type: string
    concurrency:
        required: true
        type: number
    group:
        required: true
        type: number
    person-on-events:
        required: true
        type: boolean
    token:
        required: false
        type: string
        description: GitHub token

runs:
    using: 'composite'
    steps:
        # Pre-tests

        - name: Stop/Start stack with Docker Compose
          shell: bash
          run: |
              export CLICKHOUSE_SERVER_IMAGE=${{ inputs.clickhouse-server-image }}
              docker compose -f docker-compose.dev.yml down
              docker compose -f docker-compose.dev.yml up -d

        - name: Add Kafka to /etc/hosts
          shell: bash
          run: echo "127.0.0.1 kafka" | sudo tee -a /etc/hosts

        - name: Set up Python
          uses: actions/setup-python@v4
          with:
              python-version: ${{ inputs.python-version }}
              token: ${{ inputs.token }}

        - name: Install SAML (python3-saml) dependencies
          shell: bash
          run: |
              sudo apt-get update
              sudo apt-get install libxml2-dev libxmlsec1-dev libxmlsec1-openssl

        - uses: syphar/restore-virtualenv@v1.2
          id: cache-backend-tests
          with:
              custom_cache_key_element: v1

        - uses: syphar/restore-pip-download-cache@v1
          if: steps.cache-backend-tests.outputs.cache-hit != 'true'

        - name: Install python dependencies
          if: steps.cache-backend-tests.outputs.cache-hit != 'true'
          shell: bash
          run: |
              python -m pip install -r requirements-dev.txt
              python -m pip install -r requirements.txt

        - name: Set up needed files
          shell: bash
          run: |
              mkdir -p frontend/dist
              touch frontend/dist/index.html
              touch frontend/dist/layout.html
              touch frontend/dist/exporter.html
              [ ! -f ./share/GeoLite2-City.mmdb ] && ( curl -L "https://mmdbcdn.posthog.net/" | brotli --decompress --output=./share/GeoLite2-City.mmdb )

        - name: Wait for Clickhouse & Kafka
          shell: bash
          run: bin/check_kafka_clickhouse_up

        - name: Determine if --snapshot-update should be on
          # Skip on forks (due to GITHUB_TOKEN being read-only in PRs coming from them) except for persons-on-events
          # runs, as we want to ignore snapshots diverging there
          if: github.event.pull_request.head.repo.full_name == github.repository || inputs.person-on-events == 'true'
          shell: bash
          run: echo "PYTEST_ARGS=--snapshot-update" >> $GITHUB_ENV # We can only update snapshots within the PostHog org

        # Tests

        - name: Run FOSS tests
          if: ${{ inputs.segment == 'FOSS' }}
          env:
              PERSON_ON_EVENTS_ENABLED: ${{ inputs.person-on-events }}
              GROUPS_ON_EVENTS_ENABLED: ${{ inputs.person-on-events }}
          shell: bash
          run: | # async_migrations are covered in ci-async-migrations.yml
              pytest posthog -m "not async_migrations" \
                  --splits ${{ inputs.concurrency }} --group ${{ inputs.group }} \
                  --durations=100 --durations-min=1.0 --store-durations \
                  $PYTEST_ARGS

        - name: Run EE tests
          if: ${{ inputs.segment == 'EE' }}
          env:
              PERSON_ON_EVENTS_ENABLED: ${{ inputs.person-on-events }}
              GROUPS_ON_EVENTS_ENABLED: ${{ inputs.person-on-events }}
          shell: bash
          run: | # async_migrations are covered in ci-async-migrations.yml
              pytest ee -m "not async_migrations" \
                  --splits ${{ inputs.concurrency }} --group ${{ inputs.group }} \
                  --durations=100 --durations-min=1.0 --store-durations \
                  $PYTEST_ARGS

        # Post-tests

        - name: Upload updated timing data as artifacts
          uses: actions/upload-artifact@v2
          if: ${{ inputs.segment == 'EE' && inputs.person-on-events != 'true'}}
          with:
              name: timing_data-${{ inputs.group }}
              path: .test_durations

procs:
    backend:
        shell: 'uv sync --active && bin/check_postgres_up && bin/check_kafka_clickhouse_up && ./bin/start-backend'

    celery-worker:
        shell: 'uv sync --active && bin/check_postgres_up && bin/check_kafka_clickhouse_up && ./bin/start-celery worker'

    celery-beat:
        shell: 'uv sync --active && bin/check_postgres_up && bin/check_kafka_clickhouse_up && ./bin/start-celery beat'

    plugin-server:
        shell: 'bin/check_postgres_up && bin/check_kafka_clickhouse_up && SESSION_RECORDING_V2_METADATA_SWITCHOVER=1970-01-01 ./bin/plugin-server'

    frontend:
        shell: './bin/start-frontend-vite'

    temporal-worker-general-purpose:
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue general-purpose-task-queue'

    temporal-worker-batch-exports:
        # added a sleep to give the docker stuff time to start
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue batch-exports-task-queue --metrics-port 8002'
        env:
            TEMPORAL_USE_EXTERNAL_LOGGER: 'true'

    temporal-worker-data-warehouse:
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue data-warehouse-task-queue --metrics-port 8003'

    temporal-worker-data-warehouse-compaction:
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue data-warehouse-compaction-task-queue --metrics-port 8004'

    temporal-worker-data-modeling:
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue data-modeling-task-queue --metrics-port 8005'

    temporal-worker-max-ai:
        # added a sleep to give the docker stuff time to start
        shell: 'bin/check_kafka_clickhouse_up && bin/check_temporal_up && python manage.py start_temporal_worker --task-queue max-ai-task-queue --metrics-port 8006'

    dagster:
        shell: |-
            bin/check_postgres_up && \
            bin/check_kafka_clickhouse_up && \
            dagster dev --workspace $DAGSTER_HOME/workspace.yaml -p $DAGSTER_UI_PORT

    docker-compose:
        # docker-compose makes sure the stack is up, and then follows its logs - but doesn't tear down on exit for speed
        shell: 'docker compose -f docker-compose.dev.yml up --pull always -d && docker compose -f docker-compose.dev.yml logs --tail=0 -f'

    cyclotron-janitor:
        shell: |-
            bin/check_postgres_up cyclotron && \
            bin/check_kafka_clickhouse_up && \
            bin/start-rust-service cyclotron-janitor

    cymbal:
        shell: |-
            bin/check_postgres_up && \
            bin/check_kafka_clickhouse_up && \
            bin/start-rust-service cymbal

    feature-flags:
        shell: |-
            bin/check_postgres_up posthog && \
            bin/start-rust-service feature-flags

    property-defs-rs:
        shell: |-
            bin/check_postgres_up && \
            bin/check_kafka_clickhouse_up && \
            bin/start-rust-service property-defs-rs

    capture:
        shell: |-
            bin/check_postgres_up && \
            bin/check_kafka_clickhouse_up && \
            bin/start-rust-service capture

    capture-replay:
        shell: |-
            bin/check_postgres_up && \
            bin/check_kafka_clickhouse_up && \
            bin/start-rust-service capture-replay

    migrate-postgres:
        shell: 'bin/check_postgres_up && python manage.py migrate' # This takes ~10 s

    migrate-clickhouse:
        shell: 'bin/check_kafka_clickhouse_up && python manage.py migrate_clickhouse' # This takes ~10 s too

    storybook:
        shell: 'pnpm --filter=@posthog/storybook install && pnpm run storybook'
        autostart: false

mouse_scroll_speed: 1
scrollback: 10000

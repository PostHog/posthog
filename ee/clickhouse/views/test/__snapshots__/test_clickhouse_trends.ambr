# serializer version: 1
# name: ClickhouseTestTrends.test_insight_trends_aggregate
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT count(*) AS total
  FROM events e
  WHERE team_id = 2
    AND event = '$pageview'
    AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
    AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_aggregate.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_basic
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT pdi.person_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        INNER JOIN 
          (SELECT distinct_id, 
                  argMax(person_id, version) as person_id 
           FROM person_distinct_id2 
           WHERE team_id = 2 
             AND distinct_id IN 
               (SELECT distinct_id 
                FROM events 
                WHERE team_id = 2 
                  AND event = '$pageview' 
                  AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
                  AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') ) 
           GROUP BY distinct_id 
           HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_basic.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_clean_arg
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(*) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') 
          AND (has(['val'], replaceRegexpAll(JSONExtractRaw(e.properties, 'key'), '^"|"$', '')))
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_clean_arg.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."properties" as "properties",
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC')
       AND (has(['val'], replaceRegexpAll(JSONExtractRaw(e.properties, 'key'), '^"|"$', ''))) )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(*) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.10
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '') AS value,
         count(*) as count
  FROM events e
  WHERE team_id = 2
    AND event = '$pageview'
    AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-01 00:00:00', 'UTC')
    AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
  GROUP BY value
  ORDER BY count DESC, value DESC
  LIMIT 26
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.11
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total,
         breakdown_value
  FROM
    (SELECT SUM(total) as count,
            day_start,
            breakdown_value
     FROM
       (SELECT *
        FROM
          (-- Create a table with 1 row for each interval for the requested date range
   -- This acts as a method of zero filling, i.e. when there are no data points
   -- for a given interval, we'll still have a row for the group by interval with
   -- a 0 value.
   --
   -- It's essentially a cross product of graph "ticks" and breakdown values.
   --
   -- TODO: we're relying on num_intervals, seconds_int_interval etc. being passed
   --       in as a parameter. To reduce the coupling between here and the
   --       calling code, we could perform calculations for these within the query
   --       itself based on date_to/date_from. We could also pass in the intervals
   --       explicitly, although we'll be relying on the date handling between python
   --       and ClickHouse to be the same.
   --
   -- NOTE: there is the ORDER BY ... WITH FILL Expression but I'm not sure how we'd
   --       handle the edge cases:
   --
   --          https://clickhouse.com/docs/en/sql-reference/statements/select/order-by/#orderby-with-fill
   --
   SELECT toUInt16(0) AS total,
          ticks.day_start as day_start,
          breakdown_value
           FROM
             (-- Generates all the intervals/ticks in the date range
   -- NOTE: we build this range by including successive intervals back from the
   --       upper bound, then including the lower bound in the query also.
   SELECT toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) as day_start
              FROM numbers(15)
              UNION ALL SELECT toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) as day_start) as ticks -- Zero fill for all values for the specified breakdown
  
           CROSS JOIN
             (SELECT breakdown_value
              FROM
                (SELECT ['val', 'notval'] as breakdown_value) ARRAY
              JOIN breakdown_value) as sec
           ORDER BY breakdown_value,
                    day_start
           UNION ALL SELECT count(DISTINCT person_id) as total,
                            toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) as day_start,
                            breakdown_value
           FROM
             (SELECT person_id,
                     min(timestamp) as timestamp,
                     breakdown_value
              FROM
                (SELECT pdi.person_id as person_id, timestamp, transform(ifNull(nullIf(replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', ''), ''), '$$_posthog_breakdown_null_$$'), (['val', 'notval']), (['val', 'notval']), '$$_posthog_breakdown_other_$$') as breakdown_value
                 FROM events e
                 INNER JOIN
                   (SELECT distinct_id,
                           argMax(person_id, version) as person_id
                    FROM person_distinct_id2
                    WHERE team_id = 2
                    GROUP BY distinct_id
                    HAVING argMax(is_deleted, version) = 0) as pdi ON events.distinct_id = pdi.distinct_id
                 WHERE e.team_id = 2
                   AND event = '$pageview'
                   AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
                   AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') )
              GROUP BY person_id,
                       breakdown_value) AS pdi
           GROUP BY day_start,
                    breakdown_value))
     GROUP BY day_start,
              breakdown_value
     ORDER BY breakdown_value,
              day_start)
  GROUP BY breakdown_value
  ORDER BY breakdown_value
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.12
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."properties" as "properties",
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC')
       AND (has(['val'], replaceRegexpAll(JSONExtractRaw(e.properties, 'key'), '^"|"$', ''))) )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.2
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT COUNT(DISTINCT actor_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(first_seen_timestamp, 'UTC'), 'UTC')) AS date 
        FROM 
          (SELECT pdi.person_id AS actor_id, 
                  min(timestamp) AS first_seen_timestamp 
           FROM events e 
           INNER JOIN 
             (SELECT distinct_id, 
                     argMax(person_id, version) as person_id 
              FROM person_distinct_id2 
              WHERE team_id = 2 
                AND distinct_id IN 
                  (SELECT distinct_id 
                   FROM events 
                   WHERE team_id = 2 
                     AND event = '$pageview' 
                     AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
                     AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') ) 
              GROUP BY distinct_id 
              HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
           WHERE team_id = 2 
             AND event = '$pageview' 
             AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
             AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
           GROUP BY actor_id)
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.3
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.4
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '') AS value,
         count(*) as count
  FROM events e
  WHERE team_id = 2
    AND event = '$pageview'
    AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-01 00:00:00', 'UTC')
    AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
  GROUP BY value
  ORDER BY count DESC, value DESC
  LIMIT 26
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.5
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total,
         breakdown_value
  FROM
    (SELECT SUM(total) as count,
            day_start,
            breakdown_value
     FROM
       (SELECT *
        FROM
          (-- Create a table with 1 row for each interval for the requested date range
   -- This acts as a method of zero filling, i.e. when there are no data points
   -- for a given interval, we'll still have a row for the group by interval with
   -- a 0 value.
   --
   -- It's essentially a cross product of graph "ticks" and breakdown values.
   --
   -- TODO: we're relying on num_intervals, seconds_int_interval etc. being passed
   --       in as a parameter. To reduce the coupling between here and the
   --       calling code, we could perform calculations for these within the query
   --       itself based on date_to/date_from. We could also pass in the intervals
   --       explicitly, although we'll be relying on the date handling between python
   --       and ClickHouse to be the same.
   --
   -- NOTE: there is the ORDER BY ... WITH FILL Expression but I'm not sure how we'd
   --       handle the edge cases:
   --
   --          https://clickhouse.com/docs/en/sql-reference/statements/select/order-by/#orderby-with-fill
   --
   SELECT toUInt16(0) AS total,
          ticks.day_start as day_start,
          breakdown_value
           FROM
             (-- Generates all the intervals/ticks in the date range
   -- NOTE: we build this range by including successive intervals back from the
   --       upper bound, then including the lower bound in the query also.
   SELECT toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) as day_start
              FROM numbers(15)
              UNION ALL SELECT toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) as day_start) as ticks -- Zero fill for all values for the specified breakdown
  
           CROSS JOIN
             (SELECT breakdown_value
              FROM
                (SELECT ['val', 'notval'] as breakdown_value) ARRAY
              JOIN breakdown_value) as sec
           ORDER BY breakdown_value,
                    day_start
           UNION ALL SELECT count(*) as total,
                            toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) as day_start,
                            transform(ifNull(nullIf(replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', ''), ''), '$$_posthog_breakdown_null_$$'), (['val', 'notval']), (['val', 'notval']), '$$_posthog_breakdown_other_$$') as breakdown_value
           FROM events e
           WHERE e.team_id = 2
             AND event = '$pageview'
             AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
             AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
           GROUP BY day_start,
                    breakdown_value))
     GROUP BY day_start,
              breakdown_value
     ORDER BY breakdown_value,
              day_start)
  GROUP BY breakdown_value
  ORDER BY breakdown_value
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.6
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."properties" as "properties",
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC')
       AND (has(['val'], replaceRegexpAll(JSONExtractRaw(e.properties, 'key'), '^"|"$', ''))) )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.7
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '') AS value,
         count(DISTINCT pdi.person_id) as count
  FROM events e
  INNER JOIN
    (SELECT distinct_id,
            argMax(person_id, version) as person_id
     FROM person_distinct_id2
     WHERE team_id = 2
     GROUP BY distinct_id
     HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
  INNER JOIN
    (SELECT id
     FROM person
     WHERE team_id = 2
       AND id IN
         (SELECT id
          FROM person
          WHERE team_id = 2
            AND ((has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '')))
                 AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '')))) )
     GROUP BY id
     HAVING max(is_deleted) = 0
     AND ((has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', '')))
          AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', '')))) SETTINGS optimize_aggregation_in_order = 1) person ON pdi.person_id = person.id
  WHERE team_id = 2
    AND event = '$pageview'
    AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-01 00:00:00', 'UTC')
    AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
  GROUP BY value
  ORDER BY count DESC, value DESC
  LIMIT 26
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.8
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total,
         breakdown_value
  FROM
    (SELECT SUM(total) as count,
            day_start,
            breakdown_value
     FROM
       (SELECT *
        FROM
          (-- Create a table with 1 row for each interval for the requested date range
   -- This acts as a method of zero filling, i.e. when there are no data points
   -- for a given interval, we'll still have a row for the group by interval with
   -- a 0 value.
   --
   -- It's essentially a cross product of graph "ticks" and breakdown values.
   --
   -- TODO: we're relying on num_intervals, seconds_int_interval etc. being passed
   --       in as a parameter. To reduce the coupling between here and the
   --       calling code, we could perform calculations for these within the query
   --       itself based on date_to/date_from. We could also pass in the intervals
   --       explicitly, although we'll be relying on the date handling between python
   --       and ClickHouse to be the same.
   --
   -- NOTE: there is the ORDER BY ... WITH FILL Expression but I'm not sure how we'd
   --       handle the edge cases:
   --
   --          https://clickhouse.com/docs/en/sql-reference/statements/select/order-by/#orderby-with-fill
   --
   SELECT toUInt16(0) AS total,
          ticks.day_start as day_start,
          breakdown_value
           FROM
             (-- Generates all the intervals/ticks in the date range
   -- NOTE: we build this range by including successive intervals back from the
   --       upper bound, then including the lower bound in the query also.
   SELECT toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) as day_start
              FROM numbers(15)
              UNION ALL SELECT toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) as day_start) as ticks -- Zero fill for all values for the specified breakdown
  
           CROSS JOIN
             (SELECT breakdown_value
              FROM
                (SELECT ['val', 'notval'] as breakdown_value) ARRAY
              JOIN breakdown_value) as sec
           ORDER BY breakdown_value,
                    day_start
           UNION ALL SELECT counts AS total,
                            timestamp AS day_start,
                            breakdown_value
           FROM
             (SELECT d.timestamp,
                     COUNT(DISTINCT person_id) counts,
                     breakdown_value
              FROM
                (SELECT toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS timestamp
                 FROM events e
                 WHERE team_id = 2
                   AND toDateTime(timestamp, 'UTC') >= toDateTime('2011-12-25 00:00:00', 'UTC')
                   AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
                 GROUP BY timestamp) d
              CROSS JOIN
                (SELECT toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS timestamp,
                        pdi.person_id AS person_id,
                        transform(ifNull(nullIf(replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', ''), ''), '$$_posthog_breakdown_null_$$'), (['val', 'notval']), (['val', 'notval']), '$$_posthog_breakdown_other_$$') AS breakdown_value
                 FROM events e
                 INNER JOIN
                   (SELECT distinct_id,
                           argMax(person_id, version) as person_id
                    FROM person_distinct_id2
                    WHERE team_id = 2
                    GROUP BY distinct_id
                    HAVING argMax(is_deleted, version) = 0) as pdi ON events.distinct_id = pdi.distinct_id
                 INNER JOIN
                   (SELECT id
                    FROM person
                    WHERE team_id = 2
                      AND id IN
                        (SELECT id
                         FROM person
                         WHERE team_id = 2
                           AND ((has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '')))
                                AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '')))) )
                    GROUP BY id
                    HAVING max(is_deleted) = 0
                    AND ((has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', '')))
                         AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', '')))) SETTINGS optimize_aggregation_in_order = 1) person ON person.id = pdi.person_id
                 WHERE e.team_id = 2
                   AND event = '$pageview'
                   AND toDateTime(timestamp, 'UTC') >= toDateTime('2011-12-25 00:00:00', 'UTC')
                   AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
                 GROUP BY timestamp, person_id,
                                     breakdown_value) e
              WHERE e.timestamp <= d.timestamp
                AND e.timestamp > d.timestamp - INTERVAL 6 DAY
              GROUP BY d.timestamp,
                       breakdown_value
              ORDER BY d.timestamp)
           WHERE 11111 = 11111
             AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC')
             AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') ))
     GROUP BY day_start,
              breakdown_value
     ORDER BY breakdown_value,
              day_start)
  GROUP BY breakdown_value
  ORDER BY breakdown_value
  '''
# ---
# name: ClickhouseTestTrends.test_insight_trends_cumulative.9
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."properties" as "properties",
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toDateTime(timestamp, 'UTC') >= toDateTime('2011-12-25 00:00:00', 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     INNER JOIN
       (SELECT id
        FROM person
        WHERE team_id = 2
          AND id IN
            (SELECT id
             FROM person
             WHERE team_id = 2
               AND (((has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', ''))))
                    AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(properties, 'key'), '^"|"$', '')))) )
        GROUP BY id
        HAVING max(is_deleted) = 0
        AND (((has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', ''))))
             AND (has(['some_val'], replaceRegexpAll(JSONExtractRaw(argMax(person.properties, version), 'key'), '^"|"$', '')))) SETTINGS optimize_aggregation_in_order = 1) person ON person.id = pdi.person_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toDateTime(timestamp, 'UTC') >= toDateTime('2011-12-25 00:00:00', 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC')
       AND (((has(['val'], replaceRegexpAll(JSONExtractRaw(e.properties, 'key'), '^"|"$', ''))))) )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrendsCaching.test_insight_trends_merging
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT pdi.person_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        INNER JOIN 
          (SELECT distinct_id, 
                  argMax(person_id, version) as person_id 
           FROM person_distinct_id2 
           WHERE team_id = 2 
             AND distinct_id IN 
               (SELECT distinct_id 
                FROM events 
                WHERE team_id = 2 
                  AND event = '$pageview' 
                  AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
                  AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') ) 
           GROUP BY distinct_id 
           HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsCaching.test_insight_trends_merging.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-15 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-14 00:00:00', 'UTC')), toDateTime('2012-01-15 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-14 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT pdi.person_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        INNER JOIN 
          (SELECT distinct_id, 
                  argMax(person_id, version) as person_id 
           FROM person_distinct_id2 
           WHERE team_id = 2 
             AND distinct_id IN 
               (SELECT distinct_id 
                FROM events 
                WHERE team_id = 2 
                  AND event = '$pageview' 
                  AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC') 
                  AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC') ) 
           GROUP BY distinct_id 
           HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime('2012-01-14 00:00:00', 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-15 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsCaching.test_insight_trends_merging_skipped_interval
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-14 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2011-12-31 00:00:00', 'UTC')), toDateTime('2012-01-14 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2011-12-31 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT pdi.person_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        INNER JOIN 
          (SELECT distinct_id, 
                  argMax(person_id, version) as person_id 
           FROM person_distinct_id2 
           WHERE team_id = 2 
             AND distinct_id IN 
               (SELECT distinct_id 
                FROM events 
                WHERE team_id = 2 
                  AND event = '$pageview' 
                  AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2011-12-31 00:00:00', 'UTC')), 'UTC') 
                  AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC') ) 
           GROUP BY distinct_id 
           HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2011-12-31 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-14 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsCaching.test_insight_trends_merging_skipped_interval.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2012-01-16 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2012-01-02 00:00:00', 'UTC')), toDateTime('2012-01-16 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2012-01-02 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT pdi.person_id) AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        INNER JOIN 
          (SELECT distinct_id, 
                  argMax(person_id, version) as person_id 
           FROM person_distinct_id2 
           WHERE team_id = 2 
             AND distinct_id IN 
               (SELECT distinct_id 
                FROM events 
                WHERE team_id = 2 
                  AND event = '$pageview' 
                  AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-02 00:00:00', 'UTC')), 'UTC') 
                  AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-16 23:59:59', 'UTC') ) 
           GROUP BY distinct_id 
           HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2012-01-02 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2012-01-16 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsGroups.test_aggregating_by_group
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2020-01-12 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')), toDateTime('2020-01-12 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT "$group_0") AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2020-01-12 23:59:59', 'UTC') 
          AND (NOT has([''], "$group_0")) 
          AND "$group_0" != ''
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsGroups.test_aggregating_by_group.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT $group_0 AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."$group_0" as "$group_0"
     FROM events e
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime('2020-01-02 00:00:00', 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2020-01-02 23:59:59', 'UTC')
       AND (NOT has([''], "$group_0")
            AND NOT has([''], "$group_0"))
       AND "$group_0" != '' )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---
# name: ClickhouseTestTrendsGroups.test_aggregating_by_session
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT groupArray(day_start) as date,
         groupArray(count) AS total
  FROM
    (SELECT SUM(total) AS count,
            day_start
     FROM
       (-- Creates zero values for all date axis ticks for the given date_from, date_to range
  SELECT toUInt16(0) AS total,
         toStartOfDay(toDateTime('2020-01-12 23:59:59', 'UTC')) - toIntervalDay(number) AS day_start -- Get the number of `intervals` between date_from and date_to.
  --
  -- NOTE: for week there is some unusual behavior, see:
  --       https://github.com/ClickHouse/ClickHouse/issues/7322
  --
  --       This actually aligns with what we want, as they are assuming Sunday week starts,
  --       and we'd rather have the relative week num difference. Likewise the same for
  --       "month" intervals
  --
  --       To ensure we get all relevant intervals, we add in the truncated "date_from"
  --       value.
  --
  --       This behaviour of dateDiff is different to our handling of "week" and "month"
  --       differences we are performing in python, which just considers seconds between
  --       date_from and date_to
  --
  -- TODO: Ths pattern of generating intervals is repeated in several places. Reuse this
  --       `ticks` query elsewhere.
   
        FROM numbers(dateDiff('day', toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')), toDateTime('2020-01-12 23:59:59', 'UTC'))) 
        UNION ALL -- Make sure we capture the interval date_from falls into.
  SELECT toUInt16(0) AS total, 
         toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')) 
        UNION ALL SELECT count(DISTINCT e."$session_id") AS total, 
                         toStartOfDay(toTimeZone(toDateTime(timestamp, 'UTC'), 'UTC')) AS date 
        FROM events e 
        WHERE team_id = 2 
          AND event = '$pageview' 
          AND toTimeZone(timestamp, 'UTC') >= toDateTime(toStartOfDay(toDateTime('2020-01-01 00:00:00', 'UTC')), 'UTC') 
          AND toTimeZone(timestamp, 'UTC') <= toDateTime('2020-01-12 23:59:59', 'UTC')
        GROUP BY date)
     GROUP BY day_start
     ORDER BY day_start)
  '''
# ---
# name: ClickhouseTestTrendsGroups.test_aggregating_by_session.1
  '''
  /* user_id:0 request:_snapshot_ */
  SELECT person_id AS actor_id,
         count() AS actor_value
  FROM
    (SELECT e.timestamp as timestamp,
            e."$session_id" as "$session_id",
            pdi.person_id as person_id,
            e.distinct_id as distinct_id,
            e.team_id as team_id
     FROM events e
     INNER JOIN
       (SELECT distinct_id,
               argMax(person_id, version) as person_id
        FROM person_distinct_id2
        WHERE team_id = 2
          AND distinct_id IN
            (SELECT distinct_id
             FROM events
             WHERE team_id = 2
               AND event = '$pageview'
               AND toTimeZone(timestamp, 'UTC') >= toDateTime('2020-01-02 00:00:00', 'UTC')
               AND toTimeZone(timestamp, 'UTC') <= toDateTime('2020-01-02 23:59:59', 'UTC') )
        GROUP BY distinct_id
        HAVING argMax(is_deleted, version) = 0) AS pdi ON e.distinct_id = pdi.distinct_id
     WHERE team_id = 2
       AND event = '$pageview'
       AND toTimeZone(timestamp, 'UTC') >= toDateTime('2020-01-02 00:00:00', 'UTC')
       AND toTimeZone(timestamp, 'UTC') <= toDateTime('2020-01-02 23:59:59', 'UTC') )
  GROUP BY actor_id
  ORDER BY actor_value DESC,
           actor_id DESC /* Also sorting by ID for determinism */
  LIMIT 100
  OFFSET 0
  '''
# ---

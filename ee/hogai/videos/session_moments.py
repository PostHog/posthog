import uuid
import asyncio
from dataclasses import dataclass
from datetime import datetime, timedelta
from math import ceil

from django.utils.timezone import now

import structlog
from temporalio.common import RetryPolicy, WorkflowIDReusePolicy

from posthog.constants import VIDEO_EXPORT_TASK_QUEUE
from posthog.models.exported_asset import ExportedAsset
from posthog.models.user import User
from posthog.settings.temporal import TEMPORAL_WORKFLOW_MAX_ATTEMPTS
from posthog.storage import object_storage
from posthog.sync import database_sync_to_async
from posthog.temporal.common.client import async_connect
from posthog.temporal.exports_video.workflow import VideoExportInputs, VideoExportWorkflow

from products.llm_analytics.backend.providers.gemini import GeminiProvider

from ee.hogai.session_summaries.constants import DEFAULT_EXPORT_MIME_TYPE, DEFAULT_VIDEO_UNDERSTANDING_MODEL

logger = structlog.get_logger(__name__)


@dataclass(frozen=True)
class SessionMomentInput:
    # ID to identify the moment in mappings (for example, event_uuid)
    moment_id: str
    # Timestamp to start the video from
    timestamp_s: int
    # How long the video should be
    duration_s: int
    # Prompt to validate the moment
    prompt: str


@dataclass(frozen=True)
class SessionMomentOutput(SessionMomentInput):
    # Asset ID of the stored video
    asset_id: int
    # Description of the moment, generated by LLM
    video_description: str
    # When the video was created
    created_at: datetime
    # When the video will expire
    expires_after: datetime


class SessionMomentsLLMAnalyzer:
    """Generate videos for Replay session events and analyze them with LLM"""

    def __init__(self, session_id: str, team_id: int, user: User):
        self.session_id = session_id
        self.team_id = team_id
        self.user = user

    async def analyze(
        self, moments_input: list[SessionMomentInput], expires_after_days: int, failed_moments_min_ratio: float
    ) -> list[SessionMomentOutput]:
        """
        Analyze the session moments with LLM and return mapping of moment_id to LLM analysis

        Args:
            moments_input: List of session moments to analyze
            expires_after_days: For how long to store the videos. Depends on the use case.
            failed_moments_min_ratio: If less than N% of moments were generated, fail the analysis. Depends on the use case.
        """
        # Generate mapping of moments to moment ids
        moment_id_to_moment = {moment.moment_id: moment for moment in moments_input}
        # Generate mapping of created videos (asset IDs) to moment ids
        moment_id_to_asset_id = await self._generate_videos_for_moments(
            moments_input=moments_input,
            expires_after_days=expires_after_days,
            failed_moments_min_ratio=failed_moments_min_ratio,
        )
        # Analyze videos with LLM
        results = await self._analyze_moment_videos_with_llm(
            moment_id_to_asset_id=moment_id_to_asset_id, moment_id_to_moment=moment_id_to_moment
        )
        return results

    async def _generate_videos_for_moments(
        self,
        moments_input: list[SessionMomentInput],
        expires_after_days: int,
        failed_moments_min_ratio: float,
    ) -> dict[str, int]:
        """Generate videos for moments and return mapping of moment_id to asset_id"""
        tasks = {}
        async with asyncio.TaskGroup() as tg:
            for moment in moments_input:
                tasks[moment.moment_id] = tg.create_task(
                    self._generate_video_for_single_moment(moment=moment, expires_after_days=expires_after_days)
                )
        # Collect asset IDs
        moment_to_asset_id = {}
        for moment_id, task in tasks.items():
            res = task.result()
            if isinstance(res, Exception):
                logger.exception(
                    f"Failed to generate video for moment {moment} from session {self.session_id} of team {self.team_id}: {res}"
                )
                # Not failing explicitly to avoid failing all the generations if one fails
                continue
            moment_to_asset_id[moment_id] = await task
        # Check if enough moments were generated
        expected_min_moments = ceil(len(moments_input) * failed_moments_min_ratio)
        if expected_min_moments > len(moment_to_asset_id):
            exception_message = f"Not enough moments were generated for session {self.session_id} of team {self.team_id}: {len(moment_to_asset_id)} out of {len(moments_input)}, expected at least {expected_min_moments}"
            logger.exception(exception_message)
            raise Exception(exception_message)
        return moment_to_asset_id

    def _generate_moment_video_filename(self, moment_id: str) -> str:
        """Generate a filename for a moment video"""
        return f"session-moment_{self.session_id}_{moment_id}"

    async def _generate_video_for_single_moment(
        self, moment: SessionMomentInput, expires_after_days: int
    ) -> int | Exception:
        """Generate a video for an event in Replay session and return the asset ID"""
        try:
            moment_filename = self._generate_moment_video_filename(moment_id=moment.moment_id)
            created_at = now()
            expires_after = created_at + timedelta(days=expires_after_days)
            exported_asset = await ExportedAsset.objects.acreate(
                team_id=self.team_id,
                export_format=DEFAULT_EXPORT_MIME_TYPE,
                export_context={
                    "session_recording_id": self.session_id,
                    "timestamp": moment.timestamp_s,
                    "filename": moment_filename,
                    "duration": moment.duration_s,
                    # Keeping default values
                    "mode": "screenshot",
                    "css_selector": ".replayer-wrapper",
                    "width": 1987,
                    "height": 1312,
                },
                created_by=self.user,
                created_at=created_at,
                expires_after=expires_after,
            )
            # Generate a video through Temporal workflow
            client = await async_connect()
            await client.execute_workflow(
                VideoExportWorkflow.run,
                VideoExportInputs(exported_asset_id=exported_asset.id),
                id=f"session-moment-video-export_{self.session_id}_{moment.moment_id}_{uuid.uuid4()}",
                task_queue=VIDEO_EXPORT_TASK_QUEUE,
                retry_policy=RetryPolicy(maximum_attempts=int(TEMPORAL_WORKFLOW_MAX_ATTEMPTS)),
                id_reuse_policy=WorkflowIDReusePolicy.ALLOW_DUPLICATE_FAILED_ONLY,
            )
            # Return the asset ID for later retrieval
            return exported_asset.id
        except Exception as err:  # Workflow retries exhausted
            # Let caller handle the error
            return err

    async def _get_video_bytes(self, asset_id: int) -> bytes | None:
        """Retrieve video content as bytes for an ExportedAsset ID"""
        try:
            # Fetch the asset from the database
            asset = await ExportedAsset.objects.aget(id=asset_id)
            # Get content from either database or object storage
            if asset.content:
                # Content stored directly in database
                return bytes(asset.content)
            elif asset.content_location:
                # Content stored in object storage
                return await database_sync_to_async(object_storage.read_bytes, thread_sensitive=False)(
                    asset.content_location
                )
            else:
                return None
        except ExportedAsset.DoesNotExist:
            return None

    async def _analyze_single_moment_video_with_llm(
        self,
        asset_id: int,
        moment_id: str,
        prompt: str,
    ) -> str | None | Exception:
        """Analyze a moment video with LLM"""
        try:
            video_bytes = await self._get_video_bytes(asset_id=asset_id)
            if not video_bytes:
                logger.warning(
                    f"No video bytes found for asset {asset_id} for moment {moment_id} of session {self.session_id} of team {self.team_id}"
                )
                return None
            # TODO: Remove after testing, storing for debugging
            with open(f"video_{moment_id}.mp4", "wb") as f:
                f.write(video_bytes)
            provider = GeminiProvider(model_id=DEFAULT_VIDEO_UNDERSTANDING_MODEL)
            content = provider.understand_video(
                video_bytes=video_bytes, mime_type=DEFAULT_EXPORT_MIME_TYPE, prompt=prompt
            )
            if not content:
                logger.warning(
                    f"No LLM content found for moment {moment_id} of session {self.session_id} of team {self.team_id}"
                )
                return None
            return content
        except Exception as err:
            logger.exception(
                f"Failed to analyze moment video {moment_id} of session {self.session_id} of team {self.team_id} with LLM: {err}"
            )
            return err  # Let caller handle the error

    async def _analyze_moment_videos_with_llm(
        self, moment_id_to_asset_id: dict[str, int], moment_id_to_moment: dict[str, SessionMomentInput]
    ) -> list[SessionMomentOutput]:
        """Send videos to LLM for validation and get analysis results"""
        tasks = {}
        async with asyncio.TaskGroup() as tg:
            for moment_id, asset_id in moment_id_to_asset_id.items():
                prompt = moment_id_to_moment[moment_id].prompt
                tasks[moment_id] = tg.create_task(
                    self._analyze_single_moment_video_with_llm(asset_id=asset_id, moment_id=moment_id, prompt=prompt)
                )
        results: list[SessionMomentOutput] = []
        for moment_id, task in tasks.items():
            res = task.result()
            if isinstance(res, Exception):
                logger.exception(
                    f"Failed to analyze moment video {moment_id} of session {self.session_id} of team {self.team_id} with LLM: {res}"
                )
                continue
            if not res:
                continue
            moment = moment_id_to_moment[moment_id]
            output = SessionMomentOutput(
                moment_id=moment.moment_id,
                timestamp_s=moment.timestamp_s,
                duration_s=moment.duration_s,
                prompt=moment.prompt,
                asset_id=moment_id_to_asset_id[moment_id],
                video_description=res,
            )
            results.append(output)
        # No additional check for how many moments were analyzed as they can be limited by video size
        return results

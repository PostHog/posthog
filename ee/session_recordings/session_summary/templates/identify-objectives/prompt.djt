<events_input_format>
You'll receive a list of events with columns:
- event: Type of event (e.g., $pageview, $autocapture) - signals user actions or system events
- timestamp: When the event occurred - helps track sequence and time between actions
- elements_chain_href: URL fragment interacted with - shows specific link or element targets
- elements_chain_texts: Text content of elements the user interacted with
- elements_chain_elements: Types of elements the user interacted with (clicked buttons, forms, etc.)
- $window_id: Unique identifier for browser window/tab - helps track multi-window workflows (use simplified references from window_mapping)
- $current_url: Page URL where the interaction happened on (use simplified references from url_mapping)
- $event_type: Type of interaction (e.g., click, submit) - specifies how the user interacted
- event_id: Unique identifier for the event - use this to reference specific events
- event_index: Index of the event in the session - helps understand sequence

Use these events to reconstruct the user journey. Events are provided in a chronologically order. Focus on what these events reveal about user intentions rather than the raw event data itself. 

Don't include raw `elements_chain_texts` data in your summary, but use it to improve your understanding of user goals.
</events_input_format>

<events_input>
```
{{ EVENTS_DATA|safe }}
```
</events_input>

<session_metadata_input_format>
Use session metadata to understand user engagement context:

- active_seconds: Total time user actively engaged with the application
  * <30 seconds: Very brief session, likely a single objective
  * 30-120 seconds: Short session, typically 1-3 distinct objectives
  * 120-300 seconds: Medium session, may contain 3-5 related objectives
  * >300 seconds: Extensive session, likely contains multiple complex objectives
- inactive_seconds: Periods when user wasn't interacting with the application
- click_count, keypress_count, mouse_activity_count: Interaction density
- start_url: Entry point to the application, often indicates initial user intent

Use these metrics to calibrate your analysis of user objectives and engagement quality.
</session_metadata_input_format>

<session_medata_input>
```
{{ SESSION_METADATA|safe }}
```
</session_medata_input>

<url_mapping_input_format>
URLs mapping table shows the actual URLs for simplified URL references in the events data. 

When analyzing events, use these mappings to understand the actual pages visited. For example, if an event shows 'url_1', refer to this mapping to find the actual URL. In your summary and tags, always use the actual page/feature names, not the simplified URL references. Always refer to the URL with the simplest version e.g. `posthog.com` or `posthog.com/replay`, instead of mentioning the full URL with long query parameters.
</url_mapping_input_format>

<url_mapping_input>
```
{{ URL_MAPPING|safe }}
```
</url_mapping_input>

<window_mapping_input_format>
Window IDs mapping table shows the actual browser windows/tabs IDs for simplified references in the events data.

Window IDs help track user activity across different browser windows or tabs. For example:
- If events switch from 'window_1' to 'window_2', the user switched to a different browser window/tab
- Multiple events with the same window ID indicate continuous activity in the same window/tab
- Frequent window switches might indicate comparing content or multitasking

Use this information to understand user navigation patterns and parallel browsing behavior.
</window_mapping_input_format>

<window_mapping_input>
```
{{ WINDOW_ID_MAPPING|safe }}
```
</window_mapping_input>

<identify_objectives_instructions>
CRITICAL WARNING: DO NOT hallucinate errors. Only mark events as errors when there is EXPLICIT evidence in the event data that an error occurred.

1. Identify the primary user objectives (goals) in the session. The number of objectives should be proportional to session length and complexity (as described in the `session_metadata_input_format`).

2. Each objective must represent something the user was actively trying to accomplish (e.g., "login to the application," "filter products," "complete checkout"), not technical events or metrics.

3. For each objective:
   - Provide a concise, descriptive name that captures the user's goal
   - Include a brief summary that incorporates both user actions AND any technical issues that affected this goal
   - List key actions with their corresponding event_id and error status (see Key Actions guidance below)

4. Key Actions Guidelines:
   A. General Guidelines:
      - Include 1-5 key actions per objective, scaling based on objective's complexity and duration
      - Each key action should represent a significant step in the user's journey toward their objective
      - Consolidate repeated similar actions into a single key action with frequency noted (e.g., "3 times")
      - Only create separate key actions for repeated behaviors if they represent distinct phases of interaction
      - Each key action could be an error (`error: true`, if an interruption of the user's flow occurred) or a regular user action (`error: false`), based on the guidelines below

   B. Error Guidelines:
      - Flag an event as an error ONLY if there is EXPLICIT evidence in the event data itself:
        * The event name/type explicitly indicates an error (e.g., contains 'error', 'failed', 'exception')
        * The elements_chain_texts contains error messages (e.g., "404 Not Found", "Failed to load")
      - ONLY include errors that significantly affected the user's experience or workflow:
        * INCLUDE: Errors that blocked progress (e.g., login failures, form submission errors, etc.)
        * EXCLUDE: Background errors like tracking script failures or minor UI glitches with no visible impact
      - NEVER mark these as errors:
        * Normal navigation between pages
        * Clicking different UI elements in succession, like filter changes or parameter adjustments
        * Any action without direct evidence of failure
      - Provide detailed context in error descriptions:
        * The nature of the error (e.g., API failure, validation error, timeout)
        * Potential causes if identifiable (e.g., "possibly caused by incorrect password format")
        * How the error affected subsequent user actions (e.g., "forcing user to retry" or "causing user to abandon task")
      - Error descriptions can and should be longer than regular action descriptions

   C. User Action Guidelines:
      - Focus on actions that demonstrate clear user intent
      - Keep descriptions concise but informative (e.g., "User applied filter parameters")
      - For complex actions, briefly include the outcome (e.g., "User submitted form successfully")
      - Prioritize actions that show progress toward or completion of the objective

5. Important objective guidelines:
   - DO NOT create separate objectives for error states, technical issues, or general engagement metrics
   - DO NOT create overlapping objectives - each event should generally belong to only one primary objective
   - DO create distinct objectives only when the user clearly switches to a different task or goal
   - DO incorporate error states and technical issues into the relevant user objective's summary
   - DO consider non-linear behavior where users may return to previous objectives

6. Pay special attention to:
   - The URLs visited (use url_mapping to find actual URLs)
   - Focus on meaningful user goals, not just technical events or page transitions
   - Patterns indicating user confusion, repeated attempts, or workarounds
</identify_objectives_instructions>

<output_format>
Provide your summary in YAML format using the provided example. Don't replicate the data or logic of the example, or the number of example entries. Use it ONLY to understand the format.
</output_format>

<output_example>
```
{{ SUMMARY_EXAMPLE|safe }}
```
</output_example>
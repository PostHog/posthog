<patterns_input_format>
You'll receive a list of extracted patterns in YAML format. Each pattern includes:

- pattern_id: Unique identifier for the pattern
- pattern_name: Concise name describing the reccurring issue
- pattern_description: Detailed explanation of the pattern and its impact
- severity: critical/high/medium indicating the pattern's impact level
- indicators: List of observable behaviors that confirm this pattern

Use this data to identify which specific events from the sessions match each pattern based on the pattern's indicators and the event's characteristics.
</patterns_input_format>

<patterns_input>
{{ PATTERNS|safe }}
</patterns_input>

<session_summaries_input_format>
You'll receive a list of summaries of sessions of users visiting a site or an app, using different features, navigating between pages, interacting with different elements, etc. Each session summary represents a single user journey, and is a JSON object with the following fields:

- session_id: The ID of the session
- segments: A list of segments in the session
- key_actions: A list of key actions in the session, including regular actions, failures, confusions, and abandonments.
- segment_outcomes: A list of outcomes for each segment
- session_outcome: The overall outcome of the session

Focus on the `key_actions` field which contains sessions events with their "confusion", "exception", "abandonment" flags. Use this data to assign events, where at least one flag is true/non-null, to a relevant pattern. You SHOULD NOT assign events that aren't confusions, exceptions, or abandonments.
</session_summaries_input_format>

<session_summaries_input>
```
{{ SESSION_SUMMARIES|safe }}
```
</session_summaries_input>

<pattern_assignment_instructions>
You are tasked with assigning specific problematic events from user session summaries to predefined patterns of user experience issues.

CRITICAL: Only assign events that have at least ONE of these issue flags:

- confusion: true
- exception: "blocking" or "non-blocking" 
- abandonment: true

Events without these flags are included for context only and MUST NOT be assigned to patterns.

# Step 1: Analyze Each Pattern Thoroughly

For each pattern in the input:

1.1. Understand the Pattern Core
- Identify the specific user flow or feature affected
- Note the type of friction (technical failure, UI confusion, workflow abandonment)
- Understand the impact on user journey and conversion flows

1.2. Analyze Pattern Indicators
- Understand all specific behaviors mentioned in indicators
- Note key URLs, page types, or features mentioned
- Identify action sequences that signal this pattern
- Remember: indicators are guidelines, not strict requirements

1.3. Create Pattern Profile
- Summarize in your mind: "This pattern occurs when users [action] on [feature/page] and experience [issue type]"
- Note any specific UI elements, form fields, or buttons mentioned

# Step 2: Process Session Events Systematically

For each session in the input:

2.1. Filter for Problematic Events
- Scan ONLY the key_actions field
- Keep ONLY events where AT LEAST ONE of these is true:
  - confusion: true
  - exception: "blocking" or "non-blocking"
  - abandonment: true
- Rage-clicks following errors might be symptoms, not separate issues
- Multiple rapid events might represent a single user frustration moment
- IGNORE all other events completely

2.2. Analyze Event Context
For each filtered event:
- Note the current_url and identify the feature/flow
- Read the event description carefully
- Check which issue flags are set and their values
- Look at surrounding events in the segment and segment description for context
- Identify the user's goal based on the segment

2.3. Create Event Profile
- Summarize: "User experienced [issue type] while [action] on [feature/page]"
- Note any specific elements mentioned (buttons, fields, modals)

# Step 3: Match Events to Patterns

For each problematic event identified in Step 2:

3.1. Compare Against Each Pattern
- Does the event's feature/page match the pattern's affected area?
- Does the event's issue type align with the pattern's issue type?
- Does the event description match any pattern indicators?
- Does the context suggest the same root cause as the pattern?

3.2. Evaluate Match Strength
Strong Match (assign):
- Event location matches pattern's affected feature
- Event behavior matches at least one indicator
- Issue type aligns with pattern description

Moderate Match (consider carefully):
- Event is in related feature area
- Behavior is similar but not exact match to indicators
- Issue type matches but context differs slightly

Weak Match (do not assign):
- Only vague thematic similarity
- Different feature area entirely
- Issue type doesn't align with pattern

3.3. Make Assignment Decision
- Only assign if match strength is Strong or clearly Moderate
- If an event strongly matches multiple patterns, assign to the most specific pattern
- Never assign the same event to multiple patterns
- If uncertain, prefer no assignment over incorrect assignment

# Step 4: Quality Verification

4.1. For Each Pattern's Assignments:
- Verify every assigned event has a proper active issue flag (confusion/exception/abandonment)
- Check that assignments are consistent (similar events assigned to same pattern)
- Ensure assignments match the pattern's core theme
- Remove any speculative assignments

4.2. Cross-Pattern Check:
- Ensure no event is assigned to multiple patterns
- Verify related events are grouped appropriately
- Check that assignment distribution makes sense

4.3. Validate Event IDs:
- Copy event_id strings EXACTLY as they appear in session data
- Double-check no typos or modifications

4.4. Final Review:
- Would a product manager looking at these assignments understand the pattern?
- Are the assignments actionable for fixing the issues?
- Have you avoided over-interpreting the data?

Revise your analysis if any inconsistencies are found.
</pattern_assignment_instructions>

<output_format>
Provide your pattern assignment analysis in YAML format using the provided example. Don't replicate the data, or comments, or logic of the example, or the number of example entries. Use it ONLY to understand the format.

IMPORTANT:
- Always use quotes around indicator strings that contain special characters
- Replace comparison operators with words:
  - Instead of ">3" use "more than 3" 
  - Instead of "<1" use "less than 1"
  - Instead of ">=5" use "5 or more"
- Avoid using special YAML characters (>, <, :, &, *, ?, |, -, @, `) at the beginning of unquoted strings
- When in doubt, wrap the entire indicator string in single or double quotes
</output_format>

<output_example>
```
{{ PATTERNS_ASSIGNMENT_EXAMPLE|safe }}
```
</output_example>
"""Data models for trace clustering workflow."""

from dataclasses import dataclass, field
from typing import Any, TypedDict

from posthog.temporal.llm_analytics.trace_clustering.constants import (
    DEFAULT_LOOKBACK_DAYS,
    DEFAULT_MAX_K,
    DEFAULT_MAX_SAMPLES,
    DEFAULT_MIN_K,
)


@dataclass
class ClusteringWorkflowInputs:
    """Input parameters for the daily trace clustering workflow.

    The workflow calculates window_start/window_end from lookback_days
    and passes them to the activity.
    """

    team_id: int
    lookback_days: int = DEFAULT_LOOKBACK_DAYS
    max_samples: int = DEFAULT_MAX_SAMPLES
    min_k: int = DEFAULT_MIN_K
    max_k: int = DEFAULT_MAX_K
    embedding_normalization: str = "l2"  # "none" or "l2" - whether to L2 normalize embeddings before clustering
    dimensionality_reduction_method: str = "umap"  # "none", "umap", or "pca"
    dimensionality_reduction_ndims: int = 100  # target dimensions for umap/pca (ignored if method is "none")
    run_label: str = ""  # optional label/tag for the clustering run (used as suffix in run_id for tracking experiments)
    clustering_method: str = "hdbscan"  # "hdbscan" or "kmeans"
    # Method-specific params. For HDBSCAN: min_cluster_size_fraction, min_samples
    # For k-means: min_k, max_k (uses silhouette score to pick best k)
    clustering_method_params: dict[str, Any] = field(default_factory=dict)
    visualization_method: str = "umap"  # "umap", "pca", or "tsne" - method for 2D scatter plot visualization
    # Optional property filters to scope which traces are included in clustering
    # Uses PostHog's standard property filter format (same as evaluations, feature flags, etc.)
    trace_filters: list[dict[str, Any]] = field(default_factory=list)


@dataclass
class ClusteringActivityInputs:
    """Input parameters for the clustering activity.

    Window bounds are required and calculated by the workflow.
    """

    team_id: int
    window_start: str  # ISO format, required
    window_end: str  # ISO format, required
    max_samples: int = DEFAULT_MAX_SAMPLES
    min_k: int = DEFAULT_MIN_K
    max_k: int = DEFAULT_MAX_K
    embedding_normalization: str = "l2"  # "none" or "l2" - whether to L2 normalize embeddings before clustering
    dimensionality_reduction_method: str = "umap"  # "none", "umap", or "pca"
    dimensionality_reduction_ndims: int = 100  # target dimensions for umap/pca (ignored if method is "none")
    run_label: str = ""  # optional label/tag for the clustering run (used as suffix in run_id for tracking experiments)
    clustering_method: str = "hdbscan"  # "hdbscan" or "kmeans"
    clustering_method_params: dict[str, Any] = field(default_factory=dict)
    visualization_method: str = "umap"  # "umap", "pca", or "tsne" - method for 2D scatter plot visualization
    # Optional property filters to scope which traces are included in clustering
    trace_filters: list[dict[str, Any]] = field(default_factory=list)


@dataclass
class ClusterLabel:
    """Label for a cluster generated by LLM."""

    title: str
    description: str


class TraceClusterMetadata(TypedDict):
    """Metadata for a trace within a cluster."""

    distance_to_centroid: float
    rank: int
    x: float  # UMAP 2D x coordinate for scatter plot visualization
    y: float  # UMAP 2D y coordinate for scatter plot visualization
    timestamp: str  # First event timestamp of the trace (ISO format) for efficient linking


@dataclass
class ClusterData:
    """Data structure for a cluster to be emitted in events."""

    cluster_id: int
    size: int
    title: str
    description: str
    traces: dict[str, TraceClusterMetadata]
    centroid: list[float]
    centroid_x: float  # UMAP 2D x coordinate for scatter plot visualization
    centroid_y: float  # UMAP 2D y coordinate for scatter plot visualization


@dataclass
class ClusteringMetrics:
    """Metrics from the clustering algorithm."""

    total_traces_analyzed: int = 0
    num_clusters: int = 0
    duration_seconds: float = 0.0


@dataclass
class ClusteringResult:
    """Result of the clustering workflow."""

    clustering_run_id: str
    team_id: int
    timestamp: str  # ISO format
    window_start: str  # ISO format
    window_end: str  # ISO format
    metrics: ClusteringMetrics
    clusters: list[ClusterData]


class TraceSummary(TypedDict):
    """Summary of a trace for labeling."""

    title: str
    flow_diagram: str
    bullets: str
    interesting_notes: str
    trace_timestamp: str  # First event timestamp of the trace (ISO format)


# Type aliases for data access
TraceId = str
BatchRunId = str
TraceEmbeddings = dict[TraceId, list[float]]
TraceBatchRunIds = dict[TraceId, BatchRunId]  # Maps trace_id -> batch_run_id from embeddings
TraceSummaries = dict[TraceId, TraceSummary]


@dataclass
class KMeansResult:
    """Result of k-means clustering."""

    labels: list[int]  # Cluster assignment for each sample
    centroids: list[list[float]]  # Cluster centroids


@dataclass
class HDBSCANResult:
    """Result of HDBSCAN clustering.

    Unlike k-means, HDBSCAN can assign -1 to noise points (outliers).
    Centroids are computed as the mean of cluster members.
    """

    labels: list[int]  # Cluster assignment for each sample (-1 = noise/outlier)
    centroids: list[list[float]]  # Cluster centroids (mean of members), excludes noise
    probabilities: list[float]  # Cluster membership probability per sample (0 for noise)
    num_noise_points: int  # Count of points assigned to noise cluster (-1)


@dataclass
class ClusteringComputeResult:
    """Output from the compute activity - passed to labeling and emission."""

    clustering_run_id: str
    trace_ids: list[str]
    labels: list[int]  # cluster assignment per trace (-1 = noise/outlier for HDBSCAN)
    centroids: list[list[float]]  # k centroids (excludes noise cluster)
    distances: list[list[float]]  # n_traces x k_clusters distance matrix
    coords_2d: list[list[float]]  # UMAP 2D coordinates per trace, shape (n_traces, 2)
    centroid_coords_2d: list[list[float]]  # UMAP 2D coordinates per centroid, shape (k, 2)
    probabilities: list[float]  # Cluster membership probability per sample (0 for noise)
    num_noise_points: int = 0  # Count of noise/outlier points
    batch_run_ids: dict[str, str] = field(default_factory=dict)  # trace_id -> batch_run_id for linking to summaries


@dataclass
class TraceLabelingMetadata:
    """Per-trace metadata for the labeling activity.

    Precomputed from distances matrix to avoid O(n × k) payload size.
    """

    x: float  # UMAP 2D x coordinate
    y: float  # UMAP 2D y coordinate
    distance_to_centroid: float  # Distance to own cluster's centroid
    rank: int  # Rank within cluster (1 = closest to centroid)


@dataclass
class GenerateLabelsActivityInputs:
    """Input for the LLM labeling activity.

    Contains precomputed per-trace metadata for the labeling agent.
    Payload size is O(n) instead of O(n × k) by precomputing ranks/distances.
    """

    team_id: int
    trace_ids: list[str]
    labels: list[int]  # cluster assignment per trace (-1 = noise)
    trace_metadata: list[TraceLabelingMetadata]  # per-trace: x, y, distance, rank
    centroid_coords_2d: list[list[float]]  # UMAP 2D coordinates per centroid
    window_start: str
    window_end: str
    batch_run_ids: dict[str, str] = field(default_factory=dict)  # trace_id -> batch_run_id for linking to summaries


@dataclass
class GenerateLabelsActivityOutputs:
    """Output from the LLM labeling activity."""

    cluster_labels: dict[int, ClusterLabel]


@dataclass
class ClusteringParams:
    """Parameters used for a clustering run, stored with the event for debugging/analysis."""

    clustering_method: str  # "hdbscan" or "kmeans"
    clustering_method_params: dict[str, Any]  # Method-specific params
    embedding_normalization: str  # "none" or "l2"
    dimensionality_reduction_method: str  # "none", "umap", or "pca"
    dimensionality_reduction_ndims: int  # Target dimensions
    visualization_method: str  # "umap", "pca", or "tsne"
    max_samples: int  # Max traces to sample


@dataclass
class EmitEventsActivityInputs:
    """Input for the event emission activity."""

    team_id: int
    clustering_run_id: str
    window_start: str
    window_end: str
    trace_ids: list[str]
    labels: list[int]
    centroids: list[list[float]]
    distances: list[list[float]]
    cluster_labels: dict[int, ClusterLabel]
    coords_2d: list[list[float]]  # UMAP 2D coordinates per trace
    centroid_coords_2d: list[list[float]]  # UMAP 2D coordinates per centroid
    batch_run_ids: dict[str, str] = field(default_factory=dict)  # trace_id -> batch_run_id for linking to summaries
    clustering_params: ClusteringParams | None = None  # Params used for this run

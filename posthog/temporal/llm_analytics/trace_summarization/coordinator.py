"""
Coordinator workflow for batch trace summarization.

This workflow discovers teams with LLM trace activity and spawns
child workflows to process traces for each team.
"""

import dataclasses
from datetime import datetime, timedelta

import structlog
import temporalio

from posthog.sync import database_sync_to_async
from posthog.temporal.common.base import PostHogWorkflow
from posthog.temporal.llm_analytics.trace_summarization import constants
from posthog.temporal.llm_analytics.trace_summarization.constants import (
    COORDINATOR_ACTIVITY_TIMEOUT_MINUTES,
    DEFAULT_BATCH_SIZE,
    DEFAULT_LOOKBACK_HOURS,
    DEFAULT_MAX_TRACES_PER_WINDOW,
    DEFAULT_MODE,
    DEFAULT_WINDOW_MINUTES,
    WORKFLOW_EXECUTION_TIMEOUT_MINUTES,
)
from posthog.temporal.llm_analytics.trace_summarization.models import BatchSummarizationInputs, CoordinatorResult
from posthog.temporal.llm_analytics.trace_summarization.workflow import BatchTraceSummarizationWorkflow

logger = structlog.get_logger(__name__)


@dataclasses.dataclass
class BatchTraceSummarizationCoordinatorInputs:
    """Inputs for the coordinator workflow."""

    max_traces: int = DEFAULT_MAX_TRACES_PER_WINDOW
    batch_size: int = DEFAULT_BATCH_SIZE
    mode: str = DEFAULT_MODE
    window_minutes: int = DEFAULT_WINDOW_MINUTES
    model: str | None = None
    lookback_hours: int = DEFAULT_LOOKBACK_HOURS


@dataclasses.dataclass
class TeamsWithTracesResult:
    """Result from querying teams with trace activity."""

    team_ids: list[int]


def query_teams_with_traces(
    lookback_hours: int,
    reference_time: datetime,
    allowed_team_ids: list[int] | None = None,
) -> list[int]:
    """
    Query ClickHouse for teams that have LLM trace events in the lookback window.

    Shared logic used by both the coordinator activity and manual trigger script.

    Args:
        lookback_hours: How many hours back to look from reference_time
        reference_time: Reference timestamp to query from
        allowed_team_ids: Optional list of team IDs to filter by (uses sorting key for efficiency)
    """
    from posthog.schema import AIEventType

    from posthog.clickhouse.client import sync_execute

    # Internal events generated by the summarization process - exclude from team discovery
    internal_events = {"$ai_trace_summary", "$ai_trace_clusters"}

    # Use AIEventType enum but exclude internal events that shouldn't trigger workflows
    ai_events = [event.value for event in AIEventType if event.value not in internal_events]

    # Build team filter clause - filtering by team_id uses the sorting key efficiently
    team_filter = ""
    if allowed_team_ids:
        team_filter = "AND team_id IN %(allowed_team_ids)s"

    result = sync_execute(
        f"""
        SELECT DISTINCT team_id
        FROM events
        WHERE event IN %(ai_events)s
          AND timestamp >= %(reference_time)s - INTERVAL %(lookback_hours)s HOUR
          {team_filter}
        ORDER BY team_id
        """,
        {
            "lookback_hours": lookback_hours,
            "reference_time": reference_time,
            "allowed_team_ids": allowed_team_ids or [],
            "ai_events": ai_events,
        },
    )
    return [row[0] for row in result]


@temporalio.activity.defn
async def get_teams_with_recent_traces_activity(
    inputs: BatchTraceSummarizationCoordinatorInputs,
    reference_time: datetime,
) -> TeamsWithTracesResult:
    """Query for teams that have LLM trace events in the lookback window.

    Args:
        inputs: Coordinator inputs with lookback configuration
        reference_time: Reference timestamp from workflow for idempotent queries
    """
    from posthog.temporal.llm_analytics.trace_summarization.constants import ALLOWED_TEAM_IDS

    # Pass allowlist to query for efficient filtering via sorting key
    allowed_teams = ALLOWED_TEAM_IDS if ALLOWED_TEAM_IDS else None

    @database_sync_to_async
    def get_teams():
        return query_teams_with_traces(inputs.lookback_hours, reference_time, allowed_teams)

    team_ids = await get_teams()

    logger.info(
        "Found teams with recent trace activity",
        team_count=len(team_ids),
        filtered_by_allowlist=allowed_teams is not None,
    )

    return TeamsWithTracesResult(team_ids=team_ids)


@temporalio.workflow.defn(name="batch-trace-summarization-coordinator")
class BatchTraceSummarizationCoordinatorWorkflow(PostHogWorkflow):
    """
    Coordinator workflow that discovers teams with LLM traces and spawns child workflows.

    This runs on a schedule (e.g., hourly) and automatically processes all teams
    with recent trace activity.
    """

    @staticmethod
    def parse_inputs(inputs: list[str]) -> BatchTraceSummarizationCoordinatorInputs:
        """Parse workflow inputs from string list."""
        return BatchTraceSummarizationCoordinatorInputs(
            max_traces=int(inputs[0]) if len(inputs) > 0 else DEFAULT_MAX_TRACES_PER_WINDOW,
            batch_size=int(inputs[1]) if len(inputs) > 1 else DEFAULT_BATCH_SIZE,
            mode=inputs[2] if len(inputs) > 2 else DEFAULT_MODE,
            window_minutes=int(inputs[3]) if len(inputs) > 3 else DEFAULT_WINDOW_MINUTES,
            model=inputs[4] if len(inputs) > 4 else None,
            lookback_hours=int(inputs[5]) if len(inputs) > 5 else DEFAULT_LOOKBACK_HOURS,
        )

    @temporalio.workflow.run
    async def run(self, inputs: BatchTraceSummarizationCoordinatorInputs) -> CoordinatorResult:
        """Execute coordinator workflow."""
        workflow_time = temporalio.workflow.now()

        logger.info(
            "Starting batch trace summarization coordinator",
            max_traces=inputs.max_traces,
            window_minutes=inputs.window_minutes,
            lookback_hours=inputs.lookback_hours,
        )

        # Step 1: Get teams with recent trace activity
        result = await temporalio.workflow.execute_activity(
            get_teams_with_recent_traces_activity,
            args=[inputs, workflow_time],
            schedule_to_close_timeout=timedelta(minutes=COORDINATOR_ACTIVITY_TIMEOUT_MINUTES),
            retry_policy=constants.COORDINATOR_ACTIVITY_RETRY_POLICY,
        )

        if not result.team_ids:
            logger.info("No teams with recent trace activity found")
            return CoordinatorResult(
                teams_processed=0,
                teams_failed=0,
                failed_team_ids=[],
                total_traces=0,
                total_summaries=0,
            )

        # Step 2: Spawn child workflows for each team
        total_traces = 0
        total_summaries = 0
        failed_teams = []

        for team_id in result.team_ids:
            try:
                workflow_result = await temporalio.workflow.execute_child_workflow(
                    BatchTraceSummarizationWorkflow.run,
                    BatchSummarizationInputs(
                        team_id=team_id,
                        max_traces=inputs.max_traces,
                        batch_size=inputs.batch_size,
                        mode=inputs.mode,
                        window_minutes=inputs.window_minutes,
                        model=inputs.model,
                    ),
                    id=f"batch-summarization-team-{team_id}-{temporalio.workflow.now().isoformat()}",
                    execution_timeout=timedelta(minutes=WORKFLOW_EXECUTION_TIMEOUT_MINUTES),
                    retry_policy=constants.COORDINATOR_CHILD_WORKFLOW_RETRY_POLICY,
                )

                total_traces += workflow_result.metrics.traces_queried
                total_summaries += workflow_result.metrics.summaries_generated

            except Exception as e:
                logger.exception("Failed to process team", team_id=team_id, error=str(e))
                failed_teams.append(team_id)
                # Continue with other teams

        return CoordinatorResult(
            teams_processed=len(result.team_ids),
            teams_failed=len(failed_teams),
            failed_team_ids=failed_teams,
            total_traces=total_traces,
            total_summaries=total_summaries,
        )

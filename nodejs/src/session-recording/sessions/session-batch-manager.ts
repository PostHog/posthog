import { BaseKeyStore, BaseRecordingEncryptor } from '../../recording-api/types'
import { logger } from '../../utils/logger'
import { KafkaOffsetManager } from '../kafka/offset-manager'
import { SessionBatchFileStorage } from './session-batch-file-storage'
import { SessionBatchRecorder } from './session-batch-recorder'
import { SessionConsoleLogStore } from './session-console-log-store'
import { SessionFilter } from './session-filter'
import { SessionMetadataStore } from './session-metadata-store'
import { SessionTracker } from './session-tracker'

export interface SessionBatchManagerConfig {
    /** Maximum raw size (before compression) of a batch in bytes before it should be flushed */
    maxBatchSizeBytes: number
    /** Maximum age of a batch in milliseconds before it should be flushed */
    maxBatchAgeMs: number
    /** Maximum number of events per session per batch before rate limiting */
    maxEventsPerSessionPerBatch: number
    /** Manages Kafka offset tracking and commits */
    offsetManager: KafkaOffsetManager
    /** Handles writing session batch files to storage */
    fileStorage: SessionBatchFileStorage
    /** Manages storing session metadata */
    metadataStore: SessionMetadataStore
    /** Manages storing console logs */
    consoleLogStore: SessionConsoleLogStore
    /** Session tracker for new session detection */
    sessionTracker: SessionTracker
    /** Session filter for blocking and rate-limiting sessions */
    sessionFilter: SessionFilter
    /** Key store for session encryption keys */
    keyStore: BaseKeyStore
    /** Encryptor for session recording data */
    encryptor: BaseRecordingEncryptor
}

/**
 * Coordinates the creation and flushing of session batches
 *
 * The manager ensures there is always one active batch for recording events.
 * It handles:
 * - Providing the current batch to the consumer
 * - Replacing flushed batches with new ones
 * - Providing hints for when to flush the current batch
 *
 * Each flush creates a new session batch file:
 * ```
 * Session Batch File 1 (flushed)
 * ‚îú‚îÄ‚îÄ Compressed Session Recording Block 1
 * ‚îÇ   ‚îî‚îÄ‚îÄ JSONL Session Recording Block
 * ‚îÇ       ‚îú‚îÄ‚îÄ [windowId, event1]
 * ‚îÇ       ‚îú‚îÄ‚îÄ [windowId, event2]
 * ‚îÇ       ‚îî‚îÄ‚îÄ ...
 * ‚îî‚îÄ‚îÄ ...
 *
 * Session Batch File 2 (flushed)
 * ‚îú‚îÄ‚îÄ Compressed Session Recording Block 1
 * ‚îÇ   ‚îî‚îÄ‚îÄ JSONL Session Recording Block
 * ‚îÇ       ‚îú‚îÄ‚îÄ [windowId, event1]
 * ‚îÇ       ‚îî‚îÄ‚îÄ ...
 * ‚îî‚îÄ‚îÄ ...
 *
 * Session Batch File 3 (current, returned to consumer)
 * ‚îú‚îÄ‚îÄ Compressed Session Recording Block 1
 * ‚îÇ   ‚îî‚îÄ‚îÄ JSONL Session Recording Block
 * ‚îÇ       ‚îú‚îÄ‚îÄ [windowId, event1]
 * ‚îÇ       ‚îî‚îÄ‚îÄ ... (still recording)
 * ‚îî‚îÄ‚îÄ ... (still recording)
 * ```
 */
export class SessionBatchManager {
    private currentBatch: SessionBatchRecorder
    private readonly maxBatchSizeBytes: number
    private readonly maxBatchAgeMs: number
    private readonly maxEventsPerSessionPerBatch: number
    private readonly offsetManager: KafkaOffsetManager
    private readonly fileStorage: SessionBatchFileStorage
    private readonly metadataStore: SessionMetadataStore
    private readonly consoleLogStore: SessionConsoleLogStore
    private lastFlushTime: number
    private readonly sessionTracker: SessionTracker
    private readonly sessionFilter: SessionFilter
    private readonly keyStore: BaseKeyStore
    private readonly encryptor: BaseRecordingEncryptor

    constructor(config: SessionBatchManagerConfig) {
        this.maxBatchSizeBytes = config.maxBatchSizeBytes
        this.maxBatchAgeMs = config.maxBatchAgeMs
        this.maxEventsPerSessionPerBatch = config.maxEventsPerSessionPerBatch
        this.offsetManager = config.offsetManager
        this.fileStorage = config.fileStorage
        this.metadataStore = config.metadataStore
        this.consoleLogStore = config.consoleLogStore
        this.sessionTracker = config.sessionTracker
        this.sessionFilter = config.sessionFilter
        this.keyStore = config.keyStore
        this.encryptor = config.encryptor

        this.currentBatch = new SessionBatchRecorder(
            this.offsetManager,
            this.fileStorage,
            this.metadataStore,
            this.consoleLogStore,
            this.sessionTracker,
            this.sessionFilter,
            this.keyStore,
            this.encryptor,
            this.maxEventsPerSessionPerBatch
        )
        this.lastFlushTime = Date.now()
    }

    /**
     * Returns the current batch
     */
    public getCurrentBatch(): SessionBatchRecorder {
        return this.currentBatch
    }

    /**
     * Flushes the current batch and replaces it with a new one
     */
    public async flush(): Promise<void> {
        logger.info('üîÅ', 'session_batch_manager_flushing', { batchSize: this.currentBatch.size })
        await this.currentBatch.flush()
        this.currentBatch = new SessionBatchRecorder(
            this.offsetManager,
            this.fileStorage,
            this.metadataStore,
            this.consoleLogStore,
            this.sessionTracker,
            this.sessionFilter,
            this.keyStore,
            this.encryptor,
            this.maxEventsPerSessionPerBatch
        )
        this.lastFlushTime = Date.now()
    }

    /**
     * Checks if the current batch should be flushed based on:
     * - Size of the batch exceeding maxBatchSizeBytes
     * - Age of the batch exceeding maxBatchAgeMs
     */
    public shouldFlush(): boolean {
        const batchSize = this.currentBatch.size
        const batchAge = Date.now() - this.lastFlushTime
        return batchSize >= this.maxBatchSizeBytes || batchAge >= this.maxBatchAgeMs
    }

    public discardPartitions(partitions: number[]): void {
        logger.info('üîÅ', 'session_batch_manager_discarding_partitions', { partitions })
        for (const partition of partitions) {
            this.currentBatch.discardPartition(partition)
        }
    }
}
